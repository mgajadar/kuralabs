{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "va3B1wcFn8mm"
      },
      "source": [
        "# Day 4: Building Custom MCP Servers with FastMCP\n",
        "\n",
        "## Learning Objectives\n",
        "By the end of this lesson, you will be able to:\n",
        "- Understand the fundamentals of MCP server development\n",
        "- Build custom MCP servers using the FastMCP Python SDK\n",
        "- Implement proper tool registration patterns\n",
        "- Apply authentication and authorization strategies\n",
        "- Optimize MCP server performance\n",
        "- Connect LangGraph agents to custom MCP servers\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qHzfogYan8mn"
      },
      "source": [
        "## 4.1 Introduction to Model Context Protocol (MCP)\n",
        "\n",
        "The **Model Context Protocol (MCP)** is an open protocol that enables seamless integration between LLM applications and external data sources and tools. Introduced by Anthropic in November 2024, MCP provides a standardized way to connect AI systems to resources and functionality, often described as \"the USB-C port for AI.\"\n",
        "\n",
        "### What is MCP and Why Does It Matter?\n",
        "\n",
        "Before MCP, every AI application had to build custom integrations for external tools and data sources. This led to:\n",
        "- **Fragmented ecosystem** - Each app implemented its own tool interfaces\n",
        "- **Vendor lock-in** - Tools were tied to specific AI platforms\n",
        "- **Development overhead** - Teams spent more time on integrations than core features\n",
        "- **Limited interoperability** - Difficult to share tools across different AI systems\n",
        "\n",
        "MCP solves these problems by providing a universal protocol that enables:\n",
        "\n",
        "### Key MCP Components\n",
        "\n",
        "MCP defines **three main primitives** that form the foundation of all AI-tool interactions:\n",
        "\n",
        "#### 1. **Tools** 🔧\n",
        "Executable functions that AI agents can invoke to perform actions or fetch information.\n",
        "- **Purpose**: Enable AI to take actions in the world\n",
        "- **Examples**: Send emails, query databases, perform calculations, make API calls\n",
        "- **Characteristics**: Have defined parameters, return structured results, can modify state\n",
        "\n",
        "#### 2. **Resources** 📚  \n",
        "Structured data that can be read by AI systems, similar to GET endpoints.\n",
        "- **Purpose**: Provide context and information to AI\n",
        "- **Examples**: Documentation, configuration files, datasets, knowledge bases\n",
        "- **Characteristics**: Read-only, versioned, can be cached, provide metadata\n",
        "\n",
        "#### 3. **Prompts** 💬\n",
        "Reusable templates for LLM interactions that can be invoked with parameters.\n",
        "- **Purpose**: Standardize common interaction patterns\n",
        "- **Examples**: Code review templates, writing assistants, analysis frameworks\n",
        "- **Characteristics**: Parameterized, reusable, consistent formatting\n",
        "\n",
        "### MCP Architecture: Client-Server Model\n",
        "\n",
        "```\n",
        "┌─────────────────┐    MCP Protocol    ┌─────────────────┐\n",
        "│   LLM Client    │◄──────────────────►│   MCP Server    │\n",
        "│  (LangGraph)    │                    │   (FastMCP)     │\n",
        "│                 │                    │                 │\n",
        "│ • Agent Logic   │                    │ • Tools         │\n",
        "│ • Conversations │                    │ • Resources     │\n",
        "│ • Decision      │                    │ • Business      │\n",
        "│   Making        │                    │   Logic         │\n",
        "└─────────────────┘                    └─────────────────┘\n",
        "```\n",
        "\n",
        "**Key Benefits:**\n",
        "- **Standardization**: Universal interface for all AI-tool connections\n",
        "- **Security**: Built-in authentication, authorization, and sandboxing\n",
        "- **Scalability**: Efficient client-server architecture supports many concurrent requests\n",
        "- **Flexibility**: Multiple transport protocols (stdio, HTTP, WebSocket)\n",
        "- **Composability**: Mix and match tools from different vendors seamlessly\n",
        "\n",
        "### Real-World MCP Applications\n",
        "\n",
        "**Enterprise Integration:**\n",
        "- Connect agents to CRM systems, databases, and internal APIs\n",
        "- Automate workflows across multiple business applications\n",
        "- Provide AI access to company knowledge bases and documentation\n",
        "\n",
        "**Development Tools:**\n",
        "- AI coding assistants with access to version control, testing, and deployment\n",
        "- Automated code review and documentation generation\n",
        "- Integration with IDEs, build systems, and monitoring tools\n",
        "\n",
        "**Data Science & Analytics:**\n",
        "- AI agents that can query data warehouses and visualization tools\n",
        "- Automated report generation and insight discovery\n",
        "- Integration with ML pipelines and experiment tracking\n",
        "\n",
        "### MCP vs. Other Approaches\n",
        "\n",
        "| Approach | Pros | Cons | Best For |\n",
        "|----------|------|------|----------|\n",
        "| **Direct API Integration** | Simple, direct control | Fragmented, hard to maintain | Single-tool apps |\n",
        "| **Function Calling** | Built into LLMs | Limited, vendor-specific | Simple tool usage |\n",
        "| **MCP** | Standardized, scalable, secure | Learning curve | Production systems |\n",
        "\n",
        "### Why Build MCP Servers?\n",
        "\n",
        "Building MCP servers enables you to:\n",
        "\n",
        "1. **Future-proof your tools** - Work with any MCP-compatible AI client\n",
        "2. **Reduce integration overhead** - One server, many client applications  \n",
        "3. **Enable agent ecosystems** - Compose complex workflows from simple tools\n",
        "4. **Maintain security boundaries** - Controlled access to sensitive systems\n",
        "5. **Scale efficiently** - Handle multiple AI agents with one server instance\n",
        "\n",
        "In this lesson, you'll learn to build production-ready MCP servers using **FastMCP** and integrate them with **LangGraph agents** for powerful AI workflows."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6jVIJqmpn8mo"
      },
      "source": [
        "## 4.2 Setting Up Your MCP Development Environment\n",
        "\n",
        "Building MCP servers requires a carefully configured development environment. We'll use **FastMCP 2.0** - the actively maintained Python SDK that provides a complete toolkit for the MCP ecosystem.\n",
        "\n",
        "### Installation Strategy\n",
        "\n",
        "We'll install packages in this order to avoid dependency conflicts:\n",
        "\n",
        "1. **Core MCP Development**: FastMCP for server creation\n",
        "2. **LangGraph Integration**: Official adapters for production-ready agent integration  \n",
        "3. **LLM Providers**: Support for OpenAI and Anthropic models\n",
        "4. **Supporting Libraries**: HTTP clients, async utilities, and development tools\n",
        "\n",
        "### Development Environment Setup\n",
        "\n",
        "The setup includes two main components:\n",
        "- **MCP Server Development**: Using FastMCP to create tools and resources\n",
        "- **Agent Integration**: Using LangGraph with MCP adapters for real agent workflows\n",
        "\n",
        "**Note**: This lesson uses working examples that you can run immediately. All examples work with either OpenAI or Anthropic API keys."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Complete MCP Development Environment Setup\n",
        "\n",
        "# Install required packages\n",
        "%%capture --no-stderr\n",
        "%pip install fastmcp mcp httpx langgraph langchain-mcp-adapters langchain-openai"
      ],
      "metadata": {
        "collapsed": true,
        "id": "eRMhz5-RoAFq"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Core MCP development imports\n",
        "from fastmcp import FastMCP\n",
        "import asyncio\n",
        "import httpx\n",
        "import json\n",
        "import time\n",
        "import os\n",
        "from typing import List, Dict, Optional, Any\n",
        "\n",
        "# LangGraph and MCP integration imports\n",
        "from langchain_mcp_adapters.client import MultiServerMCPClient\n",
        "from langgraph.prebuilt import create_react_agent\n",
        "from langchain_core.messages import HumanMessage\n"
      ],
      "metadata": {
        "id": "pS8LLwZWoTF4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "86f14751-f353-40d3-a924-c6223da18f70"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/jupyter_client/session.py:203: DeprecationWarning: datetime.datetime.utcnow() is deprecated and scheduled for removal in a future version. Use timezone-aware objects to represent datetimes in UTC: datetime.datetime.now(datetime.UTC).\n",
            "  return datetime.utcnow().replace(tzinfo=utc)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "33XwKiBHn8mo",
        "outputId": "b4f894cd-3a9b-4e0a-ea44-87f80b204e20"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "OPENAI_API_KEY:\t··········\n",
            "Using LLM model: gpt-4.1-mini\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/jupyter_client/session.py:203: DeprecationWarning: datetime.datetime.utcnow() is deprecated and scheduled for removal in a future version. Use timezone-aware objects to represent datetimes in UTC: datetime.datetime.now(datetime.UTC).\n",
            "  return datetime.utcnow().replace(tzinfo=utc)\n"
          ]
        }
      ],
      "source": [
        "# prompt: prompt user for openai api key and set llm variable to use the gpt-4.1-mini model\n",
        "from langchain_openai import ChatOpenAI\n",
        "from getpass import getpass\n",
        "\n",
        "os.environ[\"OPENAI_API_KEY\"] = getpass('OPENAI_API_KEY:\\t')\n",
        "\n",
        "llm = ChatOpenAI(model=\"gpt-4.1-mini\")\n",
        "\n",
        "print(f\"Using LLM model: {llm.model_name}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V_0SVVF3n8mo"
      },
      "source": [
        "### Your First MCP Server: Step-by-Step\n",
        "\n",
        "Let's build a simple but complete MCP server to understand the core concepts. This server will provide mathematical operations that AI agents can use.\n",
        "\n",
        "**Key FastMCP Concepts:**\n",
        "- `FastMCP(\"ServerName\")` - Creates a new MCP server\n",
        "- `@mcp.tool()` - Decorator that registers a function as an MCP tool\n",
        "- **Automatic Schema Generation** - FastMCP infers JSON schemas from Python type hints\n",
        "- **Error Handling** - Tools should return structured error information, not raise exceptions\n",
        "\n",
        "**Design Principles:**\n",
        "1. **Single Responsibility** - Each tool does one thing well\n",
        "2. **Clear Documentation** - Docstrings help AI understand when to use tools\n",
        "3. **Robust Validation** - Always validate inputs and handle edge cases\n",
        "4. **Structured Responses** - Return consistent, well-formatted data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X5jE4EYdn8mo",
        "outputId": "eeb27b48-365a-472f-a37b-3b73b96f99ff"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🔧 Enhanced Math MCP Server created with advanced capabilities:\n",
            "📊 Available tools:\n",
            "   • add_numbers: Addition with mathematical properties\n",
            "   • multiply_numbers: Multiplication with result analysis\n",
            "   • calculate_percentage: Percentage calculations with validation\n",
            "   • get_server_capabilities: Server introspection and documentation\n",
            "\n",
            "✨ Features:\n",
            "   • Comprehensive input validation\n",
            "   • Detailed mathematical analysis\n",
            "   • Special case detection\n",
            "   • Educational mathematical properties\n",
            "   • Structured error handling\n"
          ]
        }
      ],
      "source": [
        "# Create your first MCP server - Enhanced Math Operations\n",
        "math_mcp = FastMCP(\"EnhancedMathServer\")\n",
        "\n",
        "@math_mcp.tool(title=\"Addition Function\")\n",
        "def add_numbers(a: float, b: float) -> dict:\n",
        "    \"\"\"Add two numbers and return detailed result information.\n",
        "\n",
        "    This tool provides addition with comprehensive metadata that helps\n",
        "    AI agents understand the operation and verify results.\n",
        "\n",
        "    Args:\n",
        "        a: First number (any real number)\n",
        "        b: Second number (any real number)\n",
        "\n",
        "    Returns:\n",
        "        Dictionary with operation details, result, and metadata\n",
        "    \"\"\"\n",
        "    result = a + b\n",
        "    return {\n",
        "        \"operation\": \"addition\",\n",
        "        \"expression\": f\"{a} + {b}\",\n",
        "        \"result\": result,\n",
        "        \"operands\": {\"a\": a, \"b\": b},\n",
        "        \"operation_type\": \"arithmetic\",\n",
        "        \"properties\": {\n",
        "            \"commutative\": True,  # a + b = b + a\n",
        "            \"associative\": True,  # (a + b) + c = a + (b + c)\n",
        "            \"identity_element\": 0  # a + 0 = a\n",
        "        }\n",
        "    }\n",
        "\n",
        "@math_mcp.tool()\n",
        "def multiply_numbers(a: float, b: float) -> dict:\n",
        "    \"\"\"Multiply two numbers with comprehensive result analysis.\n",
        "\n",
        "    Args:\n",
        "        a: First number (multiplicand)\n",
        "        b: Second number (multiplier)\n",
        "\n",
        "    Returns:\n",
        "        Dictionary with multiplication details and mathematical properties\n",
        "    \"\"\"\n",
        "    result = a * b\n",
        "\n",
        "    # Analyze the result\n",
        "    analysis = {\n",
        "        \"is_positive\": result > 0,\n",
        "        \"is_negative\": result < 0,\n",
        "        \"is_zero\": result == 0,\n",
        "        \"magnitude\": abs(result)\n",
        "    }\n",
        "\n",
        "    # Special cases\n",
        "    special_cases = []\n",
        "    if a == 0 or b == 0:\n",
        "        special_cases.append(\"multiplication_by_zero\")\n",
        "    if a == 1:\n",
        "        special_cases.append(\"multiplication_by_identity\")\n",
        "    if b == 1:\n",
        "        special_cases.append(\"multiplication_by_identity\")\n",
        "    if a == -1:\n",
        "        special_cases.append(\"multiplication_by_negative_one\")\n",
        "    if b == -1:\n",
        "        special_cases.append(\"multiplication_by_negative_one\")\n",
        "\n",
        "    return {\n",
        "        \"operation\": \"multiplication\",\n",
        "        \"expression\": f\"{a} × {b}\",\n",
        "        \"result\": result,\n",
        "        \"operands\": {\"multiplicand\": a, \"multiplier\": b},\n",
        "        \"analysis\": analysis,\n",
        "        \"special_cases\": special_cases,\n",
        "        \"properties\": {\n",
        "            \"commutative\": True,  # a × b = b × a\n",
        "            \"associative\": True,  # (a × b) × c = a × (b × c)\n",
        "            \"identity_element\": 1  # a × 1 = a\n",
        "        }\n",
        "    }\n",
        "\n",
        "@math_mcp.tool()\n",
        "def calculate_percentage(value: float, percentage: float) -> dict:\n",
        "    \"\"\"Calculate what percentage of a value represents, with validation.\n",
        "\n",
        "    Args:\n",
        "        value: The base value (any real number)\n",
        "        percentage: The percentage (0-100 for normal percentages)\n",
        "\n",
        "    Returns:\n",
        "        Dictionary with percentage calculation and interpretations\n",
        "    \"\"\"\n",
        "    # Validate percentage range (allow negative for calculations)\n",
        "    if percentage < -1000 or percentage > 1000:\n",
        "        return {\n",
        "            \"error\": \"Percentage out of reasonable range (-1000% to 1000%)\",\n",
        "            \"provided_percentage\": percentage,\n",
        "            \"valid_range\": \"Typically 0-100, extended range -1000 to 1000 allowed\"\n",
        "        }\n",
        "\n",
        "    percentage_value = (value * percentage) / 100\n",
        "\n",
        "    # Provide multiple interpretations\n",
        "    interpretations = {\n",
        "        \"percentage_of_value\": f\"{percentage}% of {value} is {percentage_value}\",\n",
        "        \"fraction_form\": f\"{percentage}/100 × {value} = {percentage_value}\",\n",
        "        \"decimal_form\": f\"{percentage/100} × {value} = {percentage_value}\"\n",
        "    }\n",
        "\n",
        "    # Context about the calculation\n",
        "    context = {\n",
        "        \"is_increase\": percentage > 0 and value > 0,\n",
        "        \"is_decrease\": percentage < 0 and value > 0,\n",
        "        \"percentage_greater_than_100\": percentage > 100,\n",
        "        \"calculated_value_larger_than_original\": abs(percentage_value) > abs(value)\n",
        "    }\n",
        "\n",
        "    return {\n",
        "        \"operation\": \"percentage_calculation\",\n",
        "        \"expression\": f\"{percentage}% of {value}\",\n",
        "        \"result\": percentage_value,\n",
        "        \"inputs\": {\"value\": value, \"percentage\": percentage},\n",
        "        \"interpretations\": interpretations,\n",
        "        \"context\": context\n",
        "    }\n",
        "\n",
        "@math_mcp.resource(\"resource://server-capabilities\")\n",
        "def get_server_capabilities() -> dict:\n",
        "    \"\"\"Get information about this MCP server's mathematical capabilities.\n",
        "\n",
        "    Returns:\n",
        "        Dictionary describing available operations and server metadata\n",
        "    \"\"\"\n",
        "    return {\n",
        "        \"server_name\": \"EnhancedMathServer\",\n",
        "        \"version\": \"1.0.0\",\n",
        "        \"capabilities\": {\n",
        "            \"basic_arithmetic\": [\"addition\", \"multiplication\"],\n",
        "            \"percentage_calculations\": [\"percentage_of_value\"],\n",
        "            \"advanced_features\": [\n",
        "                \"detailed_operation_metadata\",\n",
        "                \"mathematical_property_analysis\",\n",
        "                \"input_validation_and_error_handling\",\n",
        "                \"special_case_detection\"\n",
        "            ]\n",
        "        },\n",
        "        \"supported_number_types\": [\"integers\", \"floating_point\", \"negative_numbers\"],\n",
        "        \"output_format\": \"structured_json_with_metadata\",\n",
        "        \"error_handling\": \"graceful_with_detailed_messages\",\n",
        "        \"mathematical_properties\": {\n",
        "            \"addition\": {\"commutative\": True, \"associative\": True, \"identity\": 0},\n",
        "            \"multiplication\": {\"commutative\": True, \"associative\": True, \"identity\": 1}\n",
        "        }\n",
        "    }\n",
        "\n",
        "print(\"🔧 Enhanced Math MCP Server created with advanced capabilities:\")\n",
        "print(\"📊 Available tools:\")\n",
        "print(\"   • add_numbers: Addition with mathematical properties\")\n",
        "print(\"   • multiply_numbers: Multiplication with result analysis\")\n",
        "print(\"   • calculate_percentage: Percentage calculations with validation\")\n",
        "print(\"   • get_server_capabilities: Server introspection and documentation\")\n",
        "print(\"\\n✨ Features:\")\n",
        "print(\"   • Comprehensive input validation\")\n",
        "print(\"   • Detailed mathematical analysis\")\n",
        "print(\"   • Special case detection\")\n",
        "print(\"   • Educational mathematical properties\")\n",
        "print(\"   • Structured error handling\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from fastmcp import Client\n",
        "\n",
        "client = Client(math_mcp)\n",
        "\n",
        "async with client:\n",
        "  tools = await client.list_tools()\n",
        "  resources = await client.list_resources()\n",
        "  for tool in tools:\n",
        "    print(tool.name, tool.description, tool.title)\n",
        "  print(\"-\" * 20)\n",
        "  for resource in resources:\n",
        "    print(resource.name, resource.description)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p5QjUlTQw5BZ",
        "outputId": "946894ca-4ab4-49ab-fc03-c321f421d17e"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "add_numbers Add two numbers and return detailed result information.\n",
            "\n",
            "This tool provides addition with comprehensive metadata that helps\n",
            "AI agents understand the operation and verify results.\n",
            "\n",
            "Args:\n",
            "    a: First number (any real number)\n",
            "    b: Second number (any real number)\n",
            "\n",
            "Returns:\n",
            "    Dictionary with operation details, result, and metadata Addition Function\n",
            "multiply_numbers Multiply two numbers with comprehensive result analysis.\n",
            "\n",
            "Args:\n",
            "    a: First number (multiplicand)\n",
            "    b: Second number (multiplier)\n",
            "\n",
            "Returns:\n",
            "    Dictionary with multiplication details and mathematical properties None\n",
            "calculate_percentage Calculate what percentage of a value represents, with validation.\n",
            "\n",
            "Args:\n",
            "    value: The base value (any real number)\n",
            "    percentage: The percentage (0-100 for normal percentages)\n",
            "\n",
            "Returns:\n",
            "    Dictionary with percentage calculation and interpretations None\n",
            "--------------------\n",
            "get_server_capabilities Get information about this MCP server's mathematical capabilities.\n",
            "\n",
            "Returns:\n",
            "    Dictionary describing available operations and server metadata\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/jupyter_client/session.py:203: DeprecationWarning: datetime.datetime.utcnow() is deprecated and scheduled for removal in a future version. Use timezone-aware objects to represent datetimes in UTC: datetime.datetime.now(datetime.UTC).\n",
            "  return datetime.utcnow().replace(tzinfo=utc)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kxK430KVn8mp"
      },
      "source": [
        "## 4.3 Tool Registration Patterns\n",
        "\n",
        "When creating tools, follow these best practices for clarity and safety:\n",
        "\n",
        "### 1. Clear Names and Descriptions\n",
        "- Give each tool a clear name and description\n",
        "- Use docstrings - the AI will see these when deciding to use a tool\n",
        "\n",
        "### 2. Define Input Parameters with Schemas\n",
        "- FastMCP infers JSON schema from type hints\n",
        "- You can specify complex schemas for structured inputs\n",
        "\n",
        "### 3. Input Validation\n",
        "- Always validate inputs inside your tool functions\n",
        "- Don't trust that the AI will always send perfect data\n",
        "\n",
        "### 4. Keep Tools Focused (UNIX Philosophy)\n",
        "- One tool = one task\n",
        "- Makes it easier for AI to choose the right tool"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xXDHKYrSn8mp",
        "outputId": "5f8b2e3b-3e3e-4832-b28a-1298d2150102"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🔧 Advanced Math MCP Server created with tools:\n",
            "- solve_quadratic\n",
            "- calculate_statistics\n"
          ]
        }
      ],
      "source": [
        "# Advanced MCP server with better tool patterns\n",
        "advanced_mcp = FastMCP(\"AdvancedMathServer\")\n",
        "\n",
        "@advanced_mcp.tool()\n",
        "def solve_quadratic(a: float, b: float, c: float) -> dict:\n",
        "    \"\"\"Solve a quadratic equation ax² + bx + c = 0.\n",
        "\n",
        "    Args:\n",
        "        a: Coefficient of x² (must not be zero)\n",
        "        b: Coefficient of x\n",
        "        c: Constant term\n",
        "\n",
        "    Returns:\n",
        "        Dictionary with solutions and discriminant info\n",
        "    \"\"\"\n",
        "    # Input validation\n",
        "    if a == 0:\n",
        "        raise ValueError(\"Coefficient 'a' cannot be zero for a quadratic equation\")\n",
        "\n",
        "    # Calculate discriminant\n",
        "    discriminant = b**2 - 4*a*c\n",
        "\n",
        "    result = {\n",
        "        \"equation\": f\"{a}x² + {b}x + {c} = 0\",\n",
        "        \"discriminant\": discriminant\n",
        "    }\n",
        "\n",
        "    if discriminant > 0:\n",
        "        import math\n",
        "        sqrt_discriminant = math.sqrt(discriminant)\n",
        "        x1 = (-b + sqrt_discriminant) / (2*a)\n",
        "        x2 = (-b - sqrt_discriminant) / (2*a)\n",
        "        result.update({\n",
        "            \"solutions\": [x1, x2],\n",
        "            \"type\": \"two_real_solutions\"\n",
        "        })\n",
        "    elif discriminant == 0:\n",
        "        x = -b / (2*a)\n",
        "        result.update({\n",
        "            \"solutions\": [x],\n",
        "            \"type\": \"one_real_solution\"\n",
        "        })\n",
        "    else:\n",
        "        result.update({\n",
        "            \"solutions\": [],\n",
        "            \"type\": \"no_real_solutions\"\n",
        "        })\n",
        "\n",
        "    return result\n",
        "\n",
        "@advanced_mcp.tool()\n",
        "def calculate_statistics(numbers: List[float]) -> dict:\n",
        "    \"\"\"Calculate basic statistics for a list of numbers.\n",
        "\n",
        "    Args:\n",
        "        numbers: List of numbers to analyze (must not be empty)\n",
        "\n",
        "    Returns:\n",
        "        Dictionary with mean, median, mode, std_dev, and range\n",
        "    \"\"\"\n",
        "    # Input validation\n",
        "    if not numbers:\n",
        "        raise ValueError(\"Numbers list cannot be empty\")\n",
        "\n",
        "    if not all(isinstance(n, (int, float)) for n in numbers):\n",
        "        raise ValueError(\"All elements must be numbers\")\n",
        "\n",
        "    import statistics\n",
        "\n",
        "    sorted_numbers = sorted(numbers)\n",
        "\n",
        "    result = {\n",
        "        \"count\": len(numbers),\n",
        "        \"mean\": statistics.mean(numbers),\n",
        "        \"median\": statistics.median(numbers),\n",
        "        \"min\": min(numbers),\n",
        "        \"max\": max(numbers),\n",
        "        \"range\": max(numbers) - min(numbers)\n",
        "    }\n",
        "\n",
        "    # Calculate standard deviation if we have more than one number\n",
        "    if len(numbers) > 1:\n",
        "        result[\"std_dev\"] = statistics.stdev(numbers)\n",
        "    else:\n",
        "        result[\"std_dev\"] = 0\n",
        "\n",
        "    # Try to calculate mode (may not exist for all datasets)\n",
        "    try:\n",
        "        result[\"mode\"] = statistics.mode(numbers)\n",
        "    except statistics.StatisticsError:\n",
        "        result[\"mode\"] = None\n",
        "\n",
        "    return result\n",
        "\n",
        "print(\"🔧 Advanced Math MCP Server created with tools:\")\n",
        "print(\"- solve_quadratic\")\n",
        "print(\"- calculate_statistics\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from fastmcp import Client\n",
        "\n",
        "client = Client(advanced_mcp)\n",
        "\n",
        "async with client:\n",
        "  tools = await client.list_tools()\n",
        "  resources = await client.list_resources()\n",
        "  for tool in tools:\n",
        "    print(tool.name, tool.description, tool.title)\n",
        "  print(\"-\" * 20)\n",
        "  for resource in resources:\n",
        "    print(resource.name, resource.description)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6CAvAyO-zVmf",
        "outputId": "16227569-7218-42f1-acef-ef70bf6e404a"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "solve_quadratic Solve a quadratic equation ax² + bx + c = 0.\n",
            "\n",
            "Args:\n",
            "    a: Coefficient of x² (must not be zero)\n",
            "    b: Coefficient of x\n",
            "    c: Constant term\n",
            "\n",
            "Returns:\n",
            "    Dictionary with solutions and discriminant info None\n",
            "calculate_statistics Calculate basic statistics for a list of numbers.\n",
            "\n",
            "Args:\n",
            "    numbers: List of numbers to analyze (must not be empty)\n",
            "\n",
            "Returns:\n",
            "    Dictionary with mean, median, mode, std_dev, and range None\n",
            "--------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/jupyter_client/session.py:203: DeprecationWarning: datetime.datetime.utcnow() is deprecated and scheduled for removal in a future version. Use timezone-aware objects to represent datetimes in UTC: datetime.datetime.now(datetime.UTC).\n",
            "  return datetime.utcnow().replace(tzinfo=utc)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-rUzPIy3n8mq"
      },
      "source": [
        "## 4.4 Resources: Read-Only Data Access\n",
        "\n",
        "In addition to tools, MCP supports **resources** - read-only data that can be accessed by AI systems. Resources are like GET endpoints that provide structured data."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jbYhnlU5n8mq",
        "outputId": "b498063b-b63d-413f-90f4-8bd6593f4736"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "📚 Resource MCP Server created with resources:\n",
            "- math-formula://{formula_name}\n",
            "- math-constants://\n"
          ]
        }
      ],
      "source": [
        "# Example MCP server with resources\n",
        "resource_mcp = FastMCP(\"ResourceServer\")\n",
        "\n",
        "# Sample data for resources\n",
        "MATH_FORMULAS = {\n",
        "    \"quadratic\": {\n",
        "        \"formula\": \"x = (-b ± √(b² - 4ac)) / 2a\",\n",
        "        \"description\": \"Quadratic formula for solving ax² + bx + c = 0\",\n",
        "        \"example\": \"For x² - 5x + 6 = 0: a=1, b=-5, c=6\"\n",
        "    },\n",
        "    \"distance\": {\n",
        "        \"formula\": \"d = √((x₂-x₁)² + (y₂-y₁)²)\",\n",
        "        \"description\": \"Distance between two points in 2D space\",\n",
        "        \"example\": \"Distance between (0,0) and (3,4) = 5\"\n",
        "    },\n",
        "    \"compound_interest\": {\n",
        "        \"formula\": \"A = P(1 + r/n)^(nt)\",\n",
        "        \"description\": \"Compound interest calculation\",\n",
        "        \"example\": \"P=principal, r=rate, n=compounds per year, t=time\"\n",
        "    }\n",
        "}\n",
        "\n",
        "@resource_mcp.resource(\"math-formula://{formula_name}\")\n",
        "def get_math_formula(formula_name: str) -> str:\n",
        "    \"\"\"Get mathematical formula information by name.\n",
        "\n",
        "    Available formulas: quadratic, distance, compound_interest\n",
        "    \"\"\"\n",
        "    if formula_name not in MATH_FORMULAS:\n",
        "        return f\"Formula '{formula_name}' not found. Available: {list(MATH_FORMULAS.keys())}\"\n",
        "\n",
        "    formula_info = MATH_FORMULAS[formula_name]\n",
        "    return f\"\"\"\n",
        "Formula: {formula_info['formula']}\n",
        "Description: {formula_info['description']}\n",
        "Example: {formula_info['example']}\n",
        "\"\"\".strip()\n",
        "\n",
        "@resource_mcp.resource(\"math-constants://\")\n",
        "def get_math_constants() -> str:\n",
        "    \"\"\"Get common mathematical constants.\"\"\"\n",
        "    import math\n",
        "    constants = {\n",
        "        \"π (pi)\": math.pi,\n",
        "        \"e (Euler's number)\": math.e,\n",
        "        \"φ (Golden ratio)\": (1 + math.sqrt(5)) / 2,\n",
        "        \"√2\": math.sqrt(2),\n",
        "        \"√3\": math.sqrt(3)\n",
        "    }\n",
        "\n",
        "    result = \"Mathematical Constants:\\n\"\n",
        "    for name, value in constants.items():\n",
        "        result += f\"  {name}: {value:.10f}\\n\"\n",
        "\n",
        "    return result\n",
        "\n",
        "print(\"📚 Resource MCP Server created with resources:\")\n",
        "print(\"- math-formula://{formula_name}\")\n",
        "print(\"- math-constants://\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "client = Client(resource_mcp)\n",
        "\n",
        "async with client:\n",
        "  tools = await client.list_tools()\n",
        "  resources = await client.list_resources()\n",
        "  templated_resources = await client.list_resource_templates()\n",
        "  for tool in tools:\n",
        "    print(tool.name, tool.description, tool.title)\n",
        "  print(\"-\" * 40)\n",
        "  for resource in resources:\n",
        "    print(resource.name, resource.description)\n",
        "  print(\"-\" * 40)\n",
        "  for template in templated_resources:\n",
        "    print(template.name, template.description)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CdVh-o0S1Vvi",
        "outputId": "d73a1f8b-2c69-473c-adde-e48abaeaad71"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "----------------------------------------\n",
            "get_math_constants Get common mathematical constants.\n",
            "----------------------------------------\n",
            "get_math_formula Get mathematical formula information by name.\n",
            "\n",
            "Available formulas: quadratic, distance, compound_interest\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/jupyter_client/session.py:203: DeprecationWarning: datetime.datetime.utcnow() is deprecated and scheduled for removal in a future version. Use timezone-aware objects to represent datetimes in UTC: datetime.datetime.now(datetime.UTC).\n",
            "  return datetime.utcnow().replace(tzinfo=utc)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l0WcXEgtn8mq"
      },
      "source": [
        "## 4.5 Authentication & Authorization Strategies\n",
        "\n",
        "By default, MCP does not enforce authentication - it's up to us to secure our servers. **Never deploy an MCP server without access control in production.**\n",
        "\n",
        "### Common Security Strategies:\n",
        "\n",
        "1. **API Keys or Tokens**: Simple authentication mechanism\n",
        "2. **OAuth2**: For user context and enterprise SSO\n",
        "3. **Role-Based Access Control (RBAC)**: Different permissions for different users\n",
        "4. **Tool-level Authorization**: Per-tool permission checks"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "BEUeCL03n8mq",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "72d751cf-dea3-41b7-99f1-6b9425c5213f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🔒 Secure MCP Server created with role-based access control\n",
            "Available roles: admin, user, guest\n",
            "Permissions: read, write, compute\n"
          ]
        }
      ],
      "source": [
        "# Example: MCP Server with API Key Authentication\n",
        "import os\n",
        "from functools import wraps\n",
        "\n",
        "# Secure MCP server with authentication\n",
        "secure_mcp = FastMCP(\"SecureMathServer\")\n",
        "\n",
        "# Environment variable for API key (in production, use proper secret management)\n",
        "VALID_API_KEY = os.getenv(\"MCP_API_KEY\", \"demo-key-12345\")\n",
        "\n",
        "def require_api_key(func):\n",
        "    \"\"\"Decorator to require API key authentication.\"\"\"\n",
        "    @wraps(func)\n",
        "    def wrapper(*args, **kwargs):\n",
        "        # In a real MCP server, you'd get this from the request context\n",
        "        # For demo purposes, we'll simulate it\n",
        "        provided_key = kwargs.pop('api_key', None)\n",
        "\n",
        "        if not provided_key or provided_key != VALID_API_KEY:\n",
        "            raise PermissionError(\"Invalid or missing API key\")\n",
        "\n",
        "        return func(*args, **kwargs)\n",
        "    return wrapper\n",
        "\n",
        "# User roles for RBAC\n",
        "USER_ROLES = {\n",
        "    \"admin\": [\"read\", \"write\", \"compute\"],\n",
        "    \"user\": [\"read\", \"compute\"],\n",
        "    \"guest\": [\"read\"]\n",
        "}\n",
        "\n",
        "def require_permission(permission):\n",
        "    \"\"\"Decorator to require specific permission.\"\"\"\n",
        "    def decorator(func):\n",
        "        @wraps(func)\n",
        "        def wrapper(*args, **kwargs):\n",
        "            user_role = kwargs.pop('user_role', 'guest')\n",
        "\n",
        "            if permission not in USER_ROLES.get(user_role, []):\n",
        "                raise PermissionError(f\"Role '{user_role}' does not have '{permission}' permission\")\n",
        "\n",
        "            return func(*args, **kwargs)\n",
        "        return wrapper\n",
        "    return decorator\n",
        "\n",
        "# Secure tools with authentication and authorization\n",
        "@secure_mcp.tool()\n",
        "@require_permission(\"read\")\n",
        "def get_formula_info(formula_name: str, user_role: str = \"guest\") -> str:\n",
        "    \"\"\"Get formula information (requires 'read' permission).\"\"\"\n",
        "    formulas = {\n",
        "        \"area_circle\": \"A = πr²\",\n",
        "        \"pythagorean\": \"a² + b² = c²\",\n",
        "        \"slope\": \"m = (y₂ - y₁) / (x₂ - x₁)\"\n",
        "    }\n",
        "    return formulas.get(formula_name, \"Formula not found\")\n",
        "\n",
        "@secure_mcp.tool()\n",
        "@require_permission(\"compute\")\n",
        "def secure_calculate(expression: str, user_role: str = \"guest\") -> dict:\n",
        "    \"\"\"Safely evaluate mathematical expressions (requires 'compute' permission).\"\"\"\n",
        "    import ast\n",
        "    import operator\n",
        "\n",
        "    # Safe evaluation - only allow basic math operations\n",
        "    allowed_operators = {\n",
        "        ast.Add: operator.add,\n",
        "        ast.Sub: operator.sub,\n",
        "        ast.Mult: operator.mul,\n",
        "        ast.Div: operator.truediv,\n",
        "        ast.Pow: operator.pow,\n",
        "        ast.USub: operator.neg,\n",
        "        ast.UAdd: operator.pos,\n",
        "    }\n",
        "\n",
        "    def safe_eval(node):\n",
        "        if isinstance(node, ast.Constant):  # numbers\n",
        "            return node.value\n",
        "        elif isinstance(node, ast.BinOp):  # binary operations\n",
        "            return allowed_operators[type(node.op)](safe_eval(node.left), safe_eval(node.right))\n",
        "        elif isinstance(node, ast.UnaryOp):  # unary operations\n",
        "            return allowed_operators[type(node.op)](safe_eval(node.operand))\n",
        "        else:\n",
        "            raise ValueError(f\"Unsafe operation: {type(node).__name__}\")\n",
        "\n",
        "    try:\n",
        "        tree = ast.parse(expression, mode='eval')\n",
        "        result = safe_eval(tree.body)\n",
        "        return {\n",
        "            \"expression\": expression,\n",
        "            \"result\": result,\n",
        "            \"user_role\": user_role,\n",
        "            \"status\": \"success\"\n",
        "        }\n",
        "    except Exception as e:\n",
        "        return {\n",
        "            \"expression\": expression,\n",
        "            \"error\": str(e),\n",
        "            \"user_role\": user_role,\n",
        "            \"status\": \"error\"\n",
        "        }\n",
        "\n",
        "print(\"🔒 Secure MCP Server created with role-based access control\")\n",
        "print(\"Available roles: admin, user, guest\")\n",
        "print(\"Permissions: read, write, compute\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Jx-rewQTn8mq"
      },
      "source": [
        "## 4.6 Performance Optimization Techniques\n",
        "\n",
        "MCP servers should be efficient, especially for real-time agent interactions.\n",
        "\n",
        "### Key Optimization Strategies:\n",
        "\n",
        "1. **Async I/O and Batching**: Handle multiple requests concurrently\n",
        "2. **Caching Results**: Cache expensive operations\n",
        "3. **Tool Granularity**: Balance between too many small tools vs. too few large ones\n",
        "4. **Keep Servers Stateless**: Enable horizontal scaling"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "QHCnCsk_n8mq",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b7bffd33-5734-42ce-eae5-c9cb3def62e0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "⚡ Optimized MCP Server created with performance features:\n",
            "- TTL caching for expensive operations\n",
            "- Async operations\n",
            "- Memoization for recursive calculations\n",
            "- Batch processing capabilities\n"
          ]
        }
      ],
      "source": [
        "# Performance-optimized MCP server with caching\n",
        "import time\n",
        "import asyncio\n",
        "from functools import lru_cache\n",
        "from typing import Dict, Any\n",
        "\n",
        "optimized_mcp = FastMCP(\"OptimizedServer\")\n",
        "\n",
        "# Simple in-memory cache with TTL\n",
        "class TTLCache:\n",
        "    def __init__(self, ttl_seconds: int = 300):  # 5 minutes default\n",
        "        self.cache: Dict[str, Dict[str, Any]] = {}\n",
        "        self.ttl = ttl_seconds\n",
        "\n",
        "    def get(self, key: str) -> Any:\n",
        "        if key in self.cache:\n",
        "            entry = self.cache[key]\n",
        "            if time.time() - entry['timestamp'] < self.ttl:\n",
        "                return entry['value']\n",
        "            else:\n",
        "                del self.cache[key]\n",
        "        return None\n",
        "\n",
        "    def set(self, key: str, value: Any) -> None:\n",
        "        self.cache[key] = {\n",
        "            'value': value,\n",
        "            'timestamp': time.time()\n",
        "        }\n",
        "\n",
        "    def clear(self) -> None:\n",
        "        self.cache.clear()\n",
        "\n",
        "# Create cache instance\n",
        "cache = TTLCache(ttl_seconds=60)  # 1 minute cache\n",
        "\n",
        "@optimized_mcp.tool()\n",
        "async def expensive_calculation(n: int) -> dict:\n",
        "    \"\"\"Simulate an expensive calculation with caching.\n",
        "\n",
        "    Calculates the sum of squares from 1 to n.\n",
        "    \"\"\"\n",
        "    cache_key = f\"sum_squares_{n}\"\n",
        "\n",
        "    # Check cache first\n",
        "    cached_result = cache.get(cache_key)\n",
        "    if cached_result is not None:\n",
        "        return {\n",
        "            \"n\": n,\n",
        "            \"result\": cached_result,\n",
        "            \"from_cache\": True,\n",
        "            \"calculation_time\": 0\n",
        "        }\n",
        "\n",
        "    # Perform expensive calculation\n",
        "    start_time = time.time()\n",
        "\n",
        "    # Simulate expensive work\n",
        "    await asyncio.sleep(0.1)  # Simulate network delay or complex computation\n",
        "\n",
        "    result = sum(i**2 for i in range(1, n + 1))\n",
        "\n",
        "    calculation_time = time.time() - start_time\n",
        "\n",
        "    # Cache the result\n",
        "    cache.set(cache_key, result)\n",
        "\n",
        "    return {\n",
        "        \"n\": n,\n",
        "        \"result\": result,\n",
        "        \"from_cache\": False,\n",
        "        \"calculation_time\": calculation_time\n",
        "    }\n",
        "\n",
        "@optimized_mcp.tool()\n",
        "async def batch_fibonacci(numbers: List[int]) -> dict:\n",
        "    \"\"\"Calculate Fibonacci numbers for multiple inputs efficiently.\n",
        "\n",
        "    Uses memoization to avoid recalculating the same values.\n",
        "    \"\"\"\n",
        "\n",
        "    @lru_cache(maxsize=1000)\n",
        "    def fib(n: int) -> int:\n",
        "        if n <= 1:\n",
        "            return n\n",
        "        return fib(n - 1) + fib(n - 2)\n",
        "\n",
        "    start_time = time.time()\n",
        "\n",
        "    results = {}\n",
        "    for num in numbers:\n",
        "        if num < 0:\n",
        "            results[num] = \"Error: Fibonacci not defined for negative numbers\"\n",
        "        elif num > 100:  # Prevent extremely large calculations\n",
        "            results[num] = \"Error: Number too large (max 100)\"\n",
        "        else:\n",
        "            results[num] = fib(num)\n",
        "\n",
        "    calculation_time = time.time() - start_time\n",
        "\n",
        "    return {\n",
        "        \"input_numbers\": numbers,\n",
        "        \"results\": results,\n",
        "        \"calculation_time\": calculation_time,\n",
        "        \"cache_info\": {\n",
        "            \"hits\": fib.cache_info().hits,\n",
        "            \"misses\": fib.cache_info().misses\n",
        "        }\n",
        "    }\n",
        "\n",
        "@optimized_mcp.tool()\n",
        "def get_cache_stats() -> dict:\n",
        "    \"\"\"Get cache statistics for monitoring performance.\"\"\"\n",
        "    return {\n",
        "        \"cache_size\": len(cache.cache),\n",
        "        \"cache_keys\": list(cache.cache.keys()),\n",
        "        \"ttl_seconds\": cache.ttl\n",
        "    }\n",
        "\n",
        "@optimized_mcp.tool()\n",
        "def clear_cache() -> dict:\n",
        "    \"\"\"Clear the cache (admin operation).\"\"\"\n",
        "    cache.clear()\n",
        "    return {\"status\": \"Cache cleared successfully\"}\n",
        "\n",
        "print(\"⚡ Optimized MCP Server created with performance features:\")\n",
        "print(\"- TTL caching for expensive operations\")\n",
        "print(\"- Async operations\")\n",
        "print(\"- Memoization for recursive calculations\")\n",
        "print(\"- Batch processing capabilities\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XJfpCrTrn8mr"
      },
      "source": [
        "## 4.7 Production LangGraph Agent Integration\n",
        "\n",
        "Now we'll create **real LangGraph agents** that connect to our MCP servers using the official `langchain-mcp-adapters` library. This demonstrates the complete production workflow from server development to agent deployment.\n",
        "\n",
        "### Real-World Integration Architecture\n",
        "\n",
        "```\n",
        "┌─────────────────────┐    HTTP/stdio     ┌─────────────────────┐\n",
        "│   LangGraph Agent   │◄─────────────────►│   Math MCP Server   │\n",
        "│                     │                   │                     │\n",
        "│ • GPT-4o-mini or    │    MCP Protocol   │ • add_numbers       │\n",
        "│   Claude-3.5-Sonnet │◄─────────────────►│ • multiply_numbers  │\n",
        "│ • MultiServerMCP    │                   │ • calculate_percent │\n",
        "│   Client            │    HTTP           │ • server_info       │\n",
        "│ • ReAct Agent       │◄─────────────────►│                     │\n",
        "│   Pattern           │                   │ Weather MCP Server  │\n",
        "│                     │                   │ • get_weather       │\n",
        "│                     │                   │ • forecast          │\n",
        "│                     │                   │ • compare_cities    │\n",
        "└─────────────────────┘                   └─────────────────────┘\n",
        "```\n",
        "\n",
        "### Key Integration Components\n",
        "\n",
        "1. **MultiServerMCPClient**: Official adapter for connecting to multiple MCP servers\n",
        "2. **Transport Protocols**: Support for stdio (local) and HTTP (production) transports\n",
        "3. **Agent Creation**: Using LangGraph's `create_react_agent` for natural language interaction\n",
        "4. **Tool Discovery**: Automatic detection and integration of available tools\n",
        "5. **Multi-Modal Support**: Combine different tool types (math, weather, database, etc.)\n",
        "\n",
        "### Benefits of This Architecture\n",
        "\n",
        "- **Scalability**: Each MCP server can be developed and deployed independently\n",
        "- **Modularity**: Mix and match different tool providers as needed\n",
        "- **Flexibility**: Easy to add new capabilities without changing agent code\n",
        "- **Production Ready**: HTTP transport supports load balancing and monitoring\n",
        "- **Language Agnostic**: MCP servers can be written in any language"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Create Standalone MCP Server for LangGraph Integration"
      ],
      "metadata": {
        "id": "DbxOa_oGK3SH"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "vSVQFIptn8mr"
      },
      "outputs": [],
      "source": [
        "\"\"\"\n",
        "Production Math MCP Server for LangGraph Integration\n",
        "Standalone server that supports both stdio and HTTP transports\n",
        "\"\"\"\n",
        "from fastmcp import FastMCP\n",
        "import math\n",
        "from typing import Dict, Any\n",
        "\n",
        "# Create the MCP server\n",
        "math_server = FastMCP(\"ProductionMathServer\")\n",
        "\n",
        "@math_server.tool()\n",
        "def add_numbers(a: float, b: float) -> Dict[str, Any]:\n",
        "    \"\"\"Add two numbers with detailed result information.\"\"\"\n",
        "    result = a + b\n",
        "    return {\n",
        "        \"operation\": \"addition\",\n",
        "        \"expression\": f\"{a} + {b}\",\n",
        "        \"result\": result,\n",
        "        \"operands\": {\"a\": a, \"b\": b},\n",
        "        \"properties\": {\n",
        "            \"commutative\": True,\n",
        "            \"associative\": True,\n",
        "            \"identity_element\": 0\n",
        "        }\n",
        "    }\n",
        "\n",
        "@math_server.tool()\n",
        "def multiply_numbers(a: float, b: float) -> Dict[str, Any]:\n",
        "    \"\"\"Multiply two numbers with comprehensive analysis.\"\"\"\n",
        "    result = a * b\n",
        "\n",
        "    analysis = {\n",
        "        \"is_positive\": result > 0,\n",
        "        \"is_negative\": result < 0,\n",
        "        \"is_zero\": result == 0,\n",
        "        \"magnitude\": abs(result)\n",
        "    }\n",
        "\n",
        "    special_cases = []\n",
        "    if a == 0 or b == 0:\n",
        "        special_cases.append(\"multiplication_by_zero\")\n",
        "    if abs(a) == 1:\n",
        "        special_cases.append(\"multiplication_by_identity_or_negative_one\")\n",
        "    if abs(b) == 1:\n",
        "        special_cases.append(\"multiplication_by_identity_or_negative_one\")\n",
        "\n",
        "    return {\n",
        "        \"operation\": \"multiplication\",\n",
        "        \"expression\": f\"{a} × {b}\",\n",
        "        \"result\": result,\n",
        "        \"operands\": {\"multiplicand\": a, \"multiplier\": b},\n",
        "        \"analysis\": analysis,\n",
        "        \"special_cases\": special_cases\n",
        "    }\n",
        "\n",
        "@math_server.tool()\n",
        "def calculate_power(base: float, exponent: float) -> Dict[str, Any]:\n",
        "    \"\"\"Calculate base raised to the power of exponent with safety checks.\"\"\"\n",
        "\n",
        "    # Safety checks for extreme values\n",
        "    if abs(base) > 1000 and abs(exponent) > 10:\n",
        "        return {\n",
        "            \"error\": \"Calculation too large to prevent overflow\",\n",
        "            \"base\": base,\n",
        "            \"exponent\": exponent,\n",
        "            \"max_safe_base\": 1000,\n",
        "            \"max_safe_exponent\": 10\n",
        "        }\n",
        "\n",
        "    try:\n",
        "        result = base ** exponent\n",
        "\n",
        "        # Check for overflow\n",
        "        if abs(result) > 1e10:\n",
        "            return {\n",
        "                \"error\": \"Result too large\",\n",
        "                \"base\": base,\n",
        "                \"exponent\": exponent,\n",
        "                \"max_result_magnitude\": 1e10\n",
        "            }\n",
        "\n",
        "        return {\n",
        "            \"operation\": \"exponentiation\",\n",
        "            \"expression\": f\"{base}^{exponent}\",\n",
        "            \"result\": result,\n",
        "            \"base\": base,\n",
        "            \"exponent\": exponent,\n",
        "            \"special_cases\": {\n",
        "                \"base_is_zero\": base == 0,\n",
        "                \"exponent_is_zero\": exponent == 0,\n",
        "                \"base_is_one\": base == 1,\n",
        "                \"exponent_is_one\": exponent == 1\n",
        "            }\n",
        "        }\n",
        "\n",
        "    except (OverflowError, ZeroDivisionError) as e:\n",
        "        return {\n",
        "            \"error\": f\"Mathematical error: {str(e)}\",\n",
        "            \"base\": base,\n",
        "            \"exponent\": exponent\n",
        "        }\n",
        "\n",
        "@math_server.tool()\n",
        "def solve_quadratic(a: float, b: float, c: float) -> Dict[str, Any]:\n",
        "    \"\"\"Solve quadratic equation ax² + bx + c = 0 with comprehensive analysis.\"\"\"\n",
        "\n",
        "    if a == 0:\n",
        "        if b == 0:\n",
        "            if c == 0:\n",
        "                return {\n",
        "                    \"equation\": \"0 = 0\",\n",
        "                    \"type\": \"identity\",\n",
        "                    \"solutions\": \"infinite_solutions\"\n",
        "                }\n",
        "            else:\n",
        "                return {\n",
        "                    \"equation\": f\"{c} = 0\",\n",
        "                    \"type\": \"contradiction\",\n",
        "                    \"solutions\": \"no_solutions\"\n",
        "                }\n",
        "        else:\n",
        "            # Linear equation\n",
        "            solution = -c / b\n",
        "            return {\n",
        "                \"equation\": f\"{b}x + {c} = 0\",\n",
        "                \"type\": \"linear\",\n",
        "                \"solutions\": [round(solution, 6)]\n",
        "            }\n",
        "\n",
        "    # Quadratic equation\n",
        "    discriminant = b**2 - 4*a*c\n",
        "\n",
        "    result = {\n",
        "        \"equation\": f\"{a}x² + {b}x + {c} = 0\",\n",
        "        \"coefficients\": {\"a\": a, \"b\": b, \"c\": c},\n",
        "        \"discriminant\": discriminant,\n",
        "        \"vertex\": {\n",
        "            \"x\": round(-b / (2*a), 6),\n",
        "            \"y\": round(c - (b**2) / (4*a), 6)\n",
        "        }\n",
        "    }\n",
        "\n",
        "    if discriminant > 0:\n",
        "        sqrt_discriminant = math.sqrt(discriminant)\n",
        "        x1 = (-b + sqrt_discriminant) / (2*a)\n",
        "        x2 = (-b - sqrt_discriminant) / (2*a)\n",
        "        result.update({\n",
        "            \"type\": \"two_real_solutions\",\n",
        "            \"solutions\": [round(x1, 6), round(x2, 6)]\n",
        "        })\n",
        "    elif discriminant == 0:\n",
        "        x = -b / (2*a)\n",
        "        result.update({\n",
        "            \"type\": \"one_real_solution\",\n",
        "            \"solutions\": [round(x, 6)]\n",
        "        })\n",
        "    else:\n",
        "        real_part = -b / (2*a)\n",
        "        imaginary_part = math.sqrt(-discriminant) / (2*a)\n",
        "        result.update({\n",
        "            \"type\": \"complex_solutions\",\n",
        "            \"real_part\": round(real_part, 6),\n",
        "            \"imaginary_part\": round(imaginary_part, 6),\n",
        "            \"solutions\": [\n",
        "                f\"{real_part:.3f} + {imaginary_part:.3f}i\",\n",
        "                f\"{real_part:.3f} - {imaginary_part:.3f}i\"\n",
        "            ]\n",
        "        })\n",
        "\n",
        "    return result\n",
        "\n",
        "@math_server.tool()\n",
        "def calculate_fibonacci(n: int) -> Dict[str, Any]:\n",
        "    \"\"\"Calculate the nth Fibonacci number with sequence information.\"\"\"\n",
        "\n",
        "    if n < 0:\n",
        "        return {\"error\": \"Fibonacci sequence not defined for negative numbers\"}\n",
        "\n",
        "    if n > 100:\n",
        "        return {\"error\": \"Position too large (maximum: 100)\"}\n",
        "\n",
        "    def fib(num):\n",
        "        if num <= 1:\n",
        "            return num\n",
        "        return fib(num - 1) + fib(num - 2)\n",
        "\n",
        "    result = fib(n)\n",
        "\n",
        "    # Generate sequence up to position n (limited for performance)\n",
        "    sequence_length = min(n + 1, 15)\n",
        "    sequence = [fib(i) for i in range(sequence_length)]\n",
        "\n",
        "    return {\n",
        "        \"position\": n,\n",
        "        \"fibonacci_number\": result,\n",
        "        \"sequence\": sequence,\n",
        "        \"sequence_note\": f\"Showing first {sequence_length} numbers\" if n >= 15 else \"Complete sequence\"\n",
        "    }"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Complete LangGraph Agent Integration with MCP\n",
        "\n",
        "We'll create a ReAct agent that has access to these tools using the prebuilt LangGraph option and converting the toolkit to Langchain's ecosystem using the `langchain_mcp_adapter`:"
      ],
      "metadata": {
        "id": "A5M9SB5sK_yi"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "8OENK5M6n8mr"
      },
      "outputs": [],
      "source": [
        "from fastmcp import Client\n",
        "from langgraph.prebuilt import create_react_agent\n",
        "from langchain_mcp_adapters.tools import load_mcp_tools\n",
        "\n",
        "math_client = Client(math_server)\n",
        "\n",
        "async def math_chat():\n",
        "  async with math_client:\n",
        "    tools = await load_mcp_tools(math_client.session)\n",
        "    agent = create_react_agent(model=llm, tools=tools)\n",
        "    print(\"Welcome to Advanced Math Chat!\")\n",
        "    print(\"To exit, please type 'quit' or 'q'\")\n",
        "    while True:\n",
        "      user_input = input(\"User:\\t\")\n",
        "      if user_input.lower() in [\"quit\", \"q\"]:\n",
        "        print(\"Exiting chat.\")\n",
        "        break\n",
        "      message_template = {\"messages\": [HumanMessage(content=user_input)]}\n",
        "      async for message in agent.astream(message_template):\n",
        "        print(message)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now let's test our client:"
      ],
      "metadata": {
        "id": "TrDOvOh9Ss6L"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "await math_chat()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DQOMsqhiSwWC",
        "outputId": "04340846-1d0c-4128-c45d-f1ed2920c38a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Welcome to Advanced Math Chat!\n",
            "To exit, please type 'quit' or 'q'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/jupyter_client/session.py:203: DeprecationWarning: datetime.datetime.utcnow() is deprecated and scheduled for removal in a future version. Use timezone-aware objects to represent datetimes in UTC: datetime.datetime.now(datetime.UTC).\n",
            "  return datetime.utcnow().replace(tzinfo=utc)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "User:\t2+2\n",
            "{'agent': {'messages': [AIMessage(content='', additional_kwargs={'tool_calls': [{'id': 'call_Av2qlvo4BHZIUXlU87QdoVdD', 'function': {'arguments': '{\"a\":2,\"b\":2}', 'name': 'add_numbers'}, 'type': 'function'}], 'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 18, 'prompt_tokens': 171, 'total_tokens': 189, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4.1-mini-2025-04-14', 'system_fingerprint': 'fp_a150906e27', 'id': 'chatcmpl-CEhwhOrCHUEEMDr8YyFv932dbLPyZ', 'service_tier': 'default', 'finish_reason': 'tool_calls', 'logprobs': None}, id='run--7ee72d13-ee7b-4c97-bcb8-e9aafdea5c3f-0', tool_calls=[{'name': 'add_numbers', 'args': {'a': 2, 'b': 2}, 'id': 'call_Av2qlvo4BHZIUXlU87QdoVdD', 'type': 'tool_call'}], usage_metadata={'input_tokens': 171, 'output_tokens': 18, 'total_tokens': 189, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})]}}\n",
            "{'tools': {'messages': [ToolMessage(content='{\"operation\":\"addition\",\"expression\":\"2.0 + 2.0\",\"result\":4.0,\"operands\":{\"a\":2.0,\"b\":2.0},\"properties\":{\"commutative\":true,\"associative\":true,\"identity_element\":0}}', name='add_numbers', id='f1cb0512-fdfa-4a7b-b3ac-4574f0a940c0', tool_call_id='call_Av2qlvo4BHZIUXlU87QdoVdD')]}}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/jupyter_client/session.py:203: DeprecationWarning: datetime.datetime.utcnow() is deprecated and scheduled for removal in a future version. Use timezone-aware objects to represent datetimes in UTC: datetime.datetime.now(datetime.UTC).\n",
            "  return datetime.utcnow().replace(tzinfo=utc)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'agent': {'messages': [AIMessage(content='2 + 2 = 4', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 8, 'prompt_tokens': 253, 'total_tokens': 261, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4.1-mini-2025-04-14', 'system_fingerprint': 'fp_a150906e27', 'id': 'chatcmpl-CEhwleOiUcD6v5GU694Z5NQg7GDT3', 'service_tier': 'default', 'finish_reason': 'stop', 'logprobs': None}, id='run--4d07a5e7-f491-4cf3-884d-97d19b8397eb-0', usage_metadata={'input_tokens': 253, 'output_tokens': 8, 'total_tokens': 261, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})]}}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 4.8 Multi-Server Agent Configuration\n",
        "\n",
        "One of the most powerful features of MCP is the ability to connect agents to multiple servers simultaneously. This enables agents to access diverse capabilities from different sources.\n",
        "\n",
        "### Multi-Server Architecture Benefits\n",
        "\n",
        "1. **Modularity**: Each server focuses on specific domain expertise\n",
        "2. **Scalability**: Servers can be developed and deployed independently  \n",
        "3. **Flexibility**: Mix and match different tool providers\n",
        "4. **Fault Tolerance**: If one server fails, others continue working"
      ],
      "metadata": {
        "id": "fsBG6Rkfn8ms"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%capture --no-stderr\n",
        "%pip install feedparser PyMuPDF mcp arxiv"
      ],
      "metadata": {
        "id": "lUW8vLb8YFbC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Arxiv MCP Server"
      ],
      "metadata": {
        "id": "S5aKt-iub_18"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile arxiv_server.py\n",
        "\n",
        "from fastmcp import FastMCP\n",
        "import arxiv\n",
        "from typing import List, Dict, Any\n",
        "\n",
        "mcp = FastMCP(name=\"ArxivMCP\")\n",
        "\n",
        "@mcp.tool()\n",
        "def search_arxiv(query: str, max_results: int = 5) -> List[Dict[str, Any]]:\n",
        "  \"\"\"Search ArXiv for the top n results of available research based on your query\n",
        "\n",
        "  Args:\n",
        "    query (str): The search query to find relevant ArXiv papers\n",
        "    max_results (int): The total number of results to return\n",
        "\n",
        "  Returns:\n",
        "    list: A list of the top n papers that match the query\n",
        "  \"\"\"\n",
        "  search = arxiv.Search(\n",
        "    query=query,\n",
        "    max_results=max_results,\n",
        "    sort_by=arxiv.SortCriterion.SubmittedDate\n",
        "  )\n",
        "  results = list(search.results())\n",
        "  results = [{\n",
        "      \"title\": result.title,\n",
        "      \"summary\": result.summary,\n",
        "      \"authors\": [author.name for author in result.authors],\n",
        "      \"published\": str(result.published),\n",
        "      \"updated\": str(result.updated),\n",
        "  } for result in results]\n",
        "  return results\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "  mcp.run(transport=\"stdio\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zZVRXRv3X47W",
        "outputId": "d8ed7a3f-bf74-48e1-e8ca-eff8b2a556dc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting arxiv_server.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Weather MCP Server"
      ],
      "metadata": {
        "id": "TtoFZXxkcGHj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile weather_server.py\n",
        "from mcp.server.fastmcp import FastMCP\n",
        "import httpx\n",
        "import os\n",
        "from dotenv import load_dotenv\n",
        "from fastapi import HTTPException\n",
        "from datetime import datetime\n",
        "import uvicorn\n",
        "import logging\n",
        "\n",
        "# Load environment variables from .env file\n",
        "# load_dotenv()\n",
        "WEATHER_API_KEY = \"87af948f625a41298ee211736251807\"#os.getenv(\"WEATHER_API_KEY\")\n",
        "\n",
        "# Set up logging\n",
        "logging.basicConfig(level=logging.INFO, format='%(asctime)s %(levelname)s %(message)s')\n",
        "logger = logging.getLogger(\"WeatherMCP\")\n",
        "\n",
        "# Create an MCP server named \"AdvancedWeather\"\n",
        "mcp = FastMCP(name=\"WeatherMCP\")\n",
        "\n",
        "# Helper: call WeatherAPI asynchronously\n",
        "def validate_date(dt_str: str) -> None:\n",
        "    \"\"\"\n",
        "    Ensure date string is in YYYY-MM-DD format.\n",
        "    Raises HTTPException if invalid.\n",
        "    \"\"\"\n",
        "    try:\n",
        "        datetime.strptime(dt_str, \"%Y-%m-%d\")\n",
        "    except ValueError:\n",
        "        raise HTTPException(status_code=400, detail=f\"Invalid date: {dt_str}. Use YYYY-MM-DD.\")\n",
        "\n",
        "async def fetch(endpoint: str, params: dict) -> dict:\n",
        "    \"\"\"\n",
        "    Perform async GET to WeatherAPI and return JSON.\n",
        "    Raises HTTPException on errors.\n",
        "    Enhanced: logs requests, handles non-JSON errors gracefully.\n",
        "    \"\"\"\n",
        "    if not WEATHER_API_KEY:\n",
        "        logger.error(\"Weather API key not set.\")\n",
        "        raise HTTPException(status_code=500, detail=\"Weather API key not set.\")\n",
        "\n",
        "    params[\"key\"] = WEATHER_API_KEY\n",
        "    url = f\"https://api.weatherapi.com/v1/{endpoint}\"\n",
        "    logger.info(f\"Requesting {url} with params {params}\")\n",
        "    async with httpx.AsyncClient() as client:\n",
        "        try:\n",
        "            resp = await client.get(url, params=params)\n",
        "            try:\n",
        "                data = resp.json()\n",
        "            except Exception:\n",
        "                data = None\n",
        "            if resp.status_code != 200:\n",
        "                detail = (data or {}).get(\"error\", {}).get(\"message\", resp.text)\n",
        "                logger.error(f\"WeatherAPI error {resp.status_code}: {detail}\")\n",
        "                raise HTTPException(status_code=resp.status_code, detail=detail)\n",
        "            logger.info(f\"WeatherAPI success: {url}\")\n",
        "            return data\n",
        "        except httpx.RequestError as e:\n",
        "            logger.error(f\"HTTPX request error: {e}\")\n",
        "            raise HTTPException(status_code=500, detail=f\"Request error: {e}\")\n",
        "        except Exception as e:\n",
        "            logger.error(f\"Unexpected error: {e}\")\n",
        "            raise HTTPException(status_code=500, detail=f\"Unexpected error: {e}\")\n",
        "\n",
        "\n",
        "# MCP Tools\n",
        "\n",
        "@mcp.tool()\n",
        "async def weather_current(q: str, aqi: str = \"no\") -> dict:\n",
        "    \"\"\"\n",
        "    Get current weather for a location.\n",
        "    Args:\n",
        "        q (str): Location query (city name, lat/lon, postal code, etc).\n",
        "        aqi (str): Include air quality data ('yes' or 'no').\n",
        "    Returns:\n",
        "        dict: WeatherAPI current weather JSON.\n",
        "    \"\"\"\n",
        "    if not q:\n",
        "        raise HTTPException(status_code=400, detail=\"Location (q) is required.\")\n",
        "    return await fetch(\"current.json\", {\"q\": q, \"aqi\": aqi})\n",
        "\n",
        "@mcp.tool()\n",
        "async def weather_forecast(\n",
        "    q: str,\n",
        "    days: int = 1,\n",
        "    aqi: str = \"no\",\n",
        "    alerts: str = \"no\"\n",
        ") -> dict:\n",
        "    \"\"\"\n",
        "    Get weather forecast (1–14 days) for a location.\n",
        "    Args:\n",
        "        q (str): Location query (city name, lat/lon, postal code, etc).\n",
        "        days (int): Number of days (1–14).\n",
        "        aqi (str): Include air quality ('yes' or 'no').\n",
        "        alerts (str): Include weather alerts ('yes' or 'no').\n",
        "    Returns:\n",
        "        dict: WeatherAPI forecast JSON.\n",
        "    \"\"\"\n",
        "    if not q:\n",
        "        raise HTTPException(status_code=400, detail=\"Location (q) is required.\")\n",
        "    if days < 1 or days > 14:\n",
        "        raise HTTPException(status_code=400, detail=\"'days' must be between 1 and 14.\")\n",
        "    return await fetch(\"forecast.json\", {\"q\": q, \"days\": days, \"aqi\": aqi, \"alerts\": alerts})\n",
        "\n",
        "@mcp.tool()\n",
        "async def weather_history(q: str, dt: str) -> dict:\n",
        "    \"\"\"\n",
        "    Get historical weather for a location on a given date (YYYY-MM-DD).\n",
        "    Args:\n",
        "        q (str): Location query.\n",
        "        dt (str): Date in YYYY-MM-DD format.\n",
        "    Returns:\n",
        "        dict: WeatherAPI history JSON.\n",
        "    \"\"\"\n",
        "    if not q:\n",
        "        raise HTTPException(status_code=400, detail=\"Location (q) is required.\")\n",
        "    validate_date(dt)\n",
        "    return await fetch(\"history.json\", {\"q\": q, \"dt\": dt})\n",
        "\n",
        "@mcp.tool()\n",
        "async def weather_alerts(q: str) -> dict:\n",
        "    \"\"\"\n",
        "    Get weather alerts for a location.\n",
        "    Args:\n",
        "        q (str): Location query.\n",
        "    Returns:\n",
        "        dict: WeatherAPI alerts JSON.\n",
        "    \"\"\"\n",
        "    if not q:\n",
        "        raise HTTPException(status_code=400, detail=\"Location (q) is required.\")\n",
        "    # Alerts come from forecast with alerts=yes\n",
        "    return await fetch(\"forecast.json\", {\"q\": q, \"days\": 1, \"alerts\": \"yes\"})\n",
        "\n",
        "@mcp.tool()\n",
        "async def weather_airquality(q: str) -> dict:\n",
        "    \"\"\"\n",
        "    Get air quality for a location.\n",
        "    Args:\n",
        "        q (str): Location query.\n",
        "    Returns:\n",
        "        dict: WeatherAPI air quality JSON.\n",
        "    \"\"\"\n",
        "    if not q:\n",
        "        raise HTTPException(status_code=400, detail=\"Location (q) is required.\")\n",
        "    return await fetch(\"current.json\", {\"q\": q, \"aqi\": \"yes\"})\n",
        "\n",
        "@mcp.tool()\n",
        "async def weather_astronomy(q: str, dt: str) -> dict:\n",
        "    \"\"\"\n",
        "    Get astronomy data (sunrise, sunset, moon) for a date (YYYY-MM-DD).\n",
        "    Args:\n",
        "        q (str): Location query.\n",
        "        dt (str): Date in YYYY-MM-DD format.\n",
        "    Returns:\n",
        "        dict: WeatherAPI astronomy JSON.\n",
        "    \"\"\"\n",
        "    if not q:\n",
        "        raise HTTPException(status_code=400, detail=\"Location (q) is required.\")\n",
        "    validate_date(dt)\n",
        "    return await fetch(\"astronomy.json\", {\"q\": q, \"dt\": dt})\n",
        "\n",
        "@mcp.tool()\n",
        "async def weather_search(q: str) -> dict:\n",
        "    \"\"\"\n",
        "    Search for locations matching query.\n",
        "    Args:\n",
        "        q (str): Location query.\n",
        "    Returns:\n",
        "        dict: WeatherAPI search JSON.\n",
        "    \"\"\"\n",
        "    if not q:\n",
        "        raise HTTPException(status_code=400, detail=\"Location (q) is required.\")\n",
        "    return await fetch(\"search.json\", {\"q\": q})\n",
        "\n",
        "@mcp.tool()\n",
        "async def weather_timezone(q: str) -> dict:\n",
        "    \"\"\"\n",
        "    Get timezone info for a location.\n",
        "    Args:\n",
        "        q (str): Location query.\n",
        "    Returns:\n",
        "        dict: WeatherAPI timezone JSON.\n",
        "    \"\"\"\n",
        "    if not q:\n",
        "        raise HTTPException(status_code=400, detail=\"Location (q) is required.\")\n",
        "    return await fetch(\"timezone.json\", {\"q\": q})\n",
        "\n",
        "@mcp.tool()\n",
        "async def weather_sports(q: str) -> dict:\n",
        "    \"\"\"\n",
        "    Get sports events (e.g., football, cricket) for a location.\n",
        "    Args:\n",
        "        q (str): Location query.\n",
        "    Returns:\n",
        "        dict: WeatherAPI sports JSON.\n",
        "    \"\"\"\n",
        "    if not q:\n",
        "        raise HTTPException(status_code=400, detail=\"Location (q) is required.\")\n",
        "    return await fetch(\"sports.json\", {\"q\": q})\n",
        "\n",
        "# Run the MCP server\n",
        "if __name__ == \"__main__\":\n",
        "    mcp.run(transport=\"stdio\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_JfcSY8safhx",
        "outputId": "aedf767a-ca8a-4880-b7d4-f41eb5e1e88d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting weather_server.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Smoke Test Client"
      ],
      "metadata": {
        "id": "wfDwYgyNcP-Q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile client.py\n",
        "# A client that smoketests our server\n",
        "from fastmcp import Client\n",
        "import asyncio\n",
        "\n",
        "async def main(server_path: str):\n",
        "  client = Client(server_path)\n",
        "  async with client:\n",
        "    await client.ping()\n",
        "    tools = await client.list_tools()\n",
        "    print(tools)\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "  import sys\n",
        "  server_path = sys.argv[1]\n",
        "  asyncio.run(main(server_path))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e41UClvKYVVO",
        "outputId": "ff4db67b-7f8f-46fb-bd0d-a294e33d3690"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting client.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "To test the servers, in the cell below add the server file name at the end of the call.\n",
        "\n",
        "Example:\n",
        "```bash\n",
        "python client.py weather_server.py\n",
        "```\n",
        "\n",
        "Or\n",
        "\n",
        "```bash\n",
        "python client.py arxiv_server.py\n",
        "```"
      ],
      "metadata": {
        "id": "mlVIUAivcjpv"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "4hidcKvti98d"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%bash\n",
        "\n",
        "python client.py weather_server.py"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "40l_8DOnUMeT",
        "outputId": "b594c75a-02c2-4b03-e760-b108801f1d5e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Tool(name='weather_current', title=None, description=\"\\n    Get current weather for a location.\\n    Args:\\n        q (str): Location query (city name, lat/lon, postal code, etc).\\n        aqi (str): Include air quality data ('yes' or 'no').\\n    Returns:\\n        dict: WeatherAPI current weather JSON.\\n    \", inputSchema={'properties': {'q': {'title': 'Q', 'type': 'string'}, 'aqi': {'default': 'no', 'title': 'Aqi', 'type': 'string'}}, 'required': ['q'], 'title': 'weather_currentArguments', 'type': 'object'}, outputSchema=None, annotations=None, meta=None), Tool(name='weather_forecast', title=None, description=\"\\n    Get weather forecast (1–14 days) for a location.\\n    Args:\\n        q (str): Location query (city name, lat/lon, postal code, etc).\\n        days (int): Number of days (1–14).\\n        aqi (str): Include air quality ('yes' or 'no').\\n        alerts (str): Include weather alerts ('yes' or 'no').\\n    Returns:\\n        dict: WeatherAPI forecast JSON.\\n    \", inputSchema={'properties': {'q': {'title': 'Q', 'type': 'string'}, 'days': {'default': 1, 'title': 'Days', 'type': 'integer'}, 'aqi': {'default': 'no', 'title': 'Aqi', 'type': 'string'}, 'alerts': {'default': 'no', 'title': 'Alerts', 'type': 'string'}}, 'required': ['q'], 'title': 'weather_forecastArguments', 'type': 'object'}, outputSchema=None, annotations=None, meta=None), Tool(name='weather_history', title=None, description='\\n    Get historical weather for a location on a given date (YYYY-MM-DD).\\n    Args:\\n        q (str): Location query.\\n        dt (str): Date in YYYY-MM-DD format.\\n    Returns:\\n        dict: WeatherAPI history JSON.\\n    ', inputSchema={'properties': {'q': {'title': 'Q', 'type': 'string'}, 'dt': {'title': 'Dt', 'type': 'string'}}, 'required': ['q', 'dt'], 'title': 'weather_historyArguments', 'type': 'object'}, outputSchema=None, annotations=None, meta=None), Tool(name='weather_alerts', title=None, description='\\n    Get weather alerts for a location.\\n    Args:\\n        q (str): Location query.\\n    Returns:\\n        dict: WeatherAPI alerts JSON.\\n    ', inputSchema={'properties': {'q': {'title': 'Q', 'type': 'string'}}, 'required': ['q'], 'title': 'weather_alertsArguments', 'type': 'object'}, outputSchema=None, annotations=None, meta=None), Tool(name='weather_airquality', title=None, description='\\n    Get air quality for a location.\\n    Args:\\n        q (str): Location query.\\n    Returns:\\n        dict: WeatherAPI air quality JSON.\\n    ', inputSchema={'properties': {'q': {'title': 'Q', 'type': 'string'}}, 'required': ['q'], 'title': 'weather_airqualityArguments', 'type': 'object'}, outputSchema=None, annotations=None, meta=None), Tool(name='weather_astronomy', title=None, description='\\n    Get astronomy data (sunrise, sunset, moon) for a date (YYYY-MM-DD).\\n    Args:\\n        q (str): Location query.\\n        dt (str): Date in YYYY-MM-DD format.\\n    Returns:\\n        dict: WeatherAPI astronomy JSON.\\n    ', inputSchema={'properties': {'q': {'title': 'Q', 'type': 'string'}, 'dt': {'title': 'Dt', 'type': 'string'}}, 'required': ['q', 'dt'], 'title': 'weather_astronomyArguments', 'type': 'object'}, outputSchema=None, annotations=None, meta=None), Tool(name='weather_search', title=None, description='\\n    Search for locations matching query.\\n    Args:\\n        q (str): Location query.\\n    Returns:\\n        dict: WeatherAPI search JSON.\\n    ', inputSchema={'properties': {'q': {'title': 'Q', 'type': 'string'}}, 'required': ['q'], 'title': 'weather_searchArguments', 'type': 'object'}, outputSchema=None, annotations=None, meta=None), Tool(name='weather_timezone', title=None, description='\\n    Get timezone info for a location.\\n    Args:\\n        q (str): Location query.\\n    Returns:\\n        dict: WeatherAPI timezone JSON.\\n    ', inputSchema={'properties': {'q': {'title': 'Q', 'type': 'string'}}, 'required': ['q'], 'title': 'weather_timezoneArguments', 'type': 'object'}, outputSchema=None, annotations=None, meta=None), Tool(name='weather_sports', title=None, description='\\n    Get sports events (e.g., football, cricket) for a location.\\n    Args:\\n        q (str): Location query.\\n    Returns:\\n        dict: WeatherAPI sports JSON.\\n    ', inputSchema={'properties': {'q': {'title': 'Q', 'type': 'string'}}, 'required': ['q'], 'title': 'weather_sportsArguments', 'type': 'object'}, outputSchema=None, annotations=None, meta=None)]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/jupyter_client/session.py:203: DeprecationWarning: datetime.datetime.utcnow() is deprecated and scheduled for removal in a future version. Use timezone-aware objects to represent datetimes in UTC: datetime.datetime.now(datetime.UTC).\n",
            "  return datetime.utcnow().replace(tzinfo=utc)\n",
            "2025-09-10 21:46:14,638 INFO Processing request of type PingRequest\n",
            "2025-09-10 21:46:14,641 INFO Processing request of type ListToolsRequest\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%bash\n",
        "\n",
        "python client.py arxiv_server.py"
      ],
      "metadata": {
        "id": "ZFnFyPh9ZD_o",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a165d501-36ff-406e-997c-b1b04589a1dc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Tool(name='search_arxiv', title=None, description='Search ArXiv for the top n results of available research based on your query\\n\\nArgs:\\n  query (str): The search query to find relevant ArXiv papers\\n  max_results (int): The total number of results to return\\n\\nReturns:\\n  list: A list of the top n papers that match the query', inputSchema={'properties': {'query': {'title': 'Query', 'type': 'string'}, 'max_results': {'default': 5, 'title': 'Max Results', 'type': 'integer'}}, 'required': ['query'], 'type': 'object'}, outputSchema={'properties': {'result': {'items': {'additionalProperties': True, 'type': 'object'}, 'title': 'Result', 'type': 'array'}}, 'required': ['result'], 'title': '_WrappedResult', 'type': 'object', 'x-fastmcp-wrap-result': True}, annotations=None, meta={'_fastmcp': {'tags': []}})]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/jupyter_client/session.py:203: DeprecationWarning: datetime.datetime.utcnow() is deprecated and scheduled for removal in a future version. Use timezone-aware objects to represent datetimes in UTC: datetime.datetime.now(datetime.UTC).\n",
            "  return datetime.utcnow().replace(tzinfo=utc)\n",
            "\n",
            "\n",
            "╭────────────────────────────────────────────────────────────────────────────╮\n",
            "│                                                                            │\n",
            "│        _ __ ___  _____           __  __  _____________    ____    ____     │\n",
            "│       _ __ ___ .'____/___ ______/ /_/  |/  / ____/ __ \\  |___ \\  / __ \\    │\n",
            "│      _ __ ___ / /_  / __ `/ ___/ __/ /|_/ / /   / /_/ /  ___/ / / / / /    │\n",
            "│     _ __ ___ / __/ / /_/ (__  ) /_/ /  / / /___/ ____/  /  __/_/ /_/ /     │\n",
            "│    _ __ ___ /_/    \\____/____/\\__/_/  /_/\\____/_/      /_____(*)____/      │\n",
            "│                                                                            │\n",
            "│                                                                            │\n",
            "│                                FastMCP  2.0                                │\n",
            "│                                                                            │\n",
            "│                                                                            │\n",
            "│                 🖥️  Server name:     ArxivMCP                               │\n",
            "│                 📦 Transport:       STDIO                                  │\n",
            "│                                                                            │\n",
            "│                 🏎️  FastMCP version: 2.12.2                                 │\n",
            "│                 🤝 MCP SDK version: 1.13.1                                 │\n",
            "│                                                                            │\n",
            "│                 📚 Docs:            https://gofastmcp.com                  │\n",
            "│                 🚀 Deploy:          https://fastmcp.cloud                  │\n",
            "│                                                                            │\n",
            "╰────────────────────────────────────────────────────────────────────────────╯\n",
            "\n",
            "\n",
            "[09/10/25 21:46:22] INFO     Starting MCP server 'ArxivMCP' with  server.py:1493\n",
            "                             transport 'stdio'                                  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile multiserver_mcp_client.py\n",
        "\n",
        "from langchain_mcp_adapters.client import MultiServerMCPClient\n",
        "from langgraph.prebuilt import create_react_agent\n",
        "import asyncio\n",
        "\n",
        "client = MultiServerMCPClient(\n",
        "    {\n",
        "        \"weather\": {\n",
        "            \"command\": \"python\",\n",
        "            # Make sure to update to the full absolute path to your math_server.py file\n",
        "            \"args\": [\"weather_server.py\"],\n",
        "            \"transport\": \"stdio\",\n",
        "        },\n",
        "        \"arxiv\": {\n",
        "            \"command\": \"python\",\n",
        "            \"args\": [\"arxiv_server.py\"],\n",
        "            \"transport\": \"stdio\"\n",
        "        }\n",
        "    }\n",
        ")\n",
        "\n",
        "async def main(user_input: str):\n",
        "  tools = await client.get_tools()\n",
        "  agent = create_react_agent(\"openai:gpt-4.1-mini\", tools)\n",
        "  print(\"Welcome to the weather and arxiv AI agent. Ask a question about the weather or research.\")\n",
        "  message_template = {\"messages\": [user_input]}\n",
        "\n",
        "  async for message in agent.astream(message_template):\n",
        "    print(message)\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "  import sys\n",
        "  user_input = sys.argv[1] if len(sys.argv) > 1 else \"What is the weather in New York?\"\n",
        "  asyncio.run(main(user_input))\n"
      ],
      "metadata": {
        "id": "Dxdd6OaQn8ms",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a93a2a66-b55e-4edc-8f47-dec61c6b049c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting multiserver_mcp_client.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%bash\n",
        "\n",
        "python multiserver_mcp_client.py \"What is the latest research available on AI and what's the weather in New York like?\""
      ],
      "metadata": {
        "id": "uhluV4w_eS28",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1383a048-7b4a-46a1-eba8-40fa1a2ee303"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Welcome to the weather and arxiv AI agent. Ask a question about the weather or research.\n",
            "{'agent': {'messages': [AIMessage(content='', additional_kwargs={'tool_calls': [{'id': 'call_Y24jaUI54PwEmt1ArfL7iVkf', 'function': {'arguments': '{\"query\": \"Artificial Intelligence\", \"max_results\": 5}', 'name': 'search_arxiv'}, 'type': 'function'}, {'id': 'call_w5YdUzjMcQFuQnAdbUozvj5S', 'function': {'arguments': '{\"q\": \"New York\"}', 'name': 'weather_current'}, 'type': 'function'}], 'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 52, 'prompt_tokens': 688, 'total_tokens': 740, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4.1-mini-2025-04-14', 'system_fingerprint': 'fp_4fce0778af', 'id': 'chatcmpl-CEMw7tzj3yR8ZzJ5roTSdYtfyd7eO', 'service_tier': 'default', 'finish_reason': 'tool_calls', 'logprobs': None}, id='run--3559c16c-8d87-4e46-b640-868434269dcc-0', tool_calls=[{'name': 'search_arxiv', 'args': {'query': 'Artificial Intelligence', 'max_results': 5}, 'id': 'call_Y24jaUI54PwEmt1ArfL7iVkf', 'type': 'tool_call'}, {'name': 'weather_current', 'args': {'q': 'New York'}, 'id': 'call_w5YdUzjMcQFuQnAdbUozvj5S', 'type': 'tool_call'}], usage_metadata={'input_tokens': 688, 'output_tokens': 52, 'total_tokens': 740, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})]}}\n",
            "{'tools': {'messages': [ToolMessage(content='[{\"title\":\"Mini-o3: Scaling Up Reasoning Patterns and Interaction Turns for Visual Search\",\"summary\":\"Recent advances in large multimodal models have leveraged image-based tools\\\\nwith reinforcement learning to tackle visual problems. However, existing\\\\nopen-source approaches often exhibit monotonous reasoning patterns and allow\\\\nonly a limited number of interaction turns, making them inadequate for\\\\ndifficult tasks that require trial-and-error exploration. In this work, we\\\\naddress this limitation by scaling up tool-based interactions and introduce\\\\nMini-o3, a system that executes deep, multi-turn reasoning -- spanning tens of\\\\nsteps -- and achieves state-of-the-art performance on challenging visual search\\\\ntasks. Our recipe for reproducing OpenAI o3-style behaviors comprises three key\\\\ncomponents. First, we construct the Visual Probe Dataset, a collection of\\\\nthousands of challenging visual search problems designed for exploratory\\\\nreasoning. Second, we develop an iterative data collection pipeline to obtain\\\\ncold-start trajectories that exhibit diverse reasoning patterns, including\\\\ndepth-first search, trial-and-error, and goal maintenance. Third, we propose an\\\\nover-turn masking strategy that prevents penalization of over-turn responses\\\\n(those that hit the maximum number of turns) during reinforcement learning,\\\\nthereby balancing training-time efficiency with test-time scalability. Despite\\\\ntraining with an upper bound of only six interaction turns, our model generates\\\\ntrajectories that naturally scale to tens of turns at inference time, with\\\\naccuracy improving as the number of turns increases. Extensive experiments\\\\ndemonstrate that Mini-o3 produces rich reasoning patterns and deep thinking\\\\npaths, effectively solving challenging visual search problems.\",\"authors\":[\"Xin Lai\",\"Junyi Li\",\"Wei Li\",\"Tao Liu\",\"Tianjian Li\",\"Hengshuang Zhao\"],\"published\":\"2025-09-09 17:54:21+00:00\",\"updated\":\"2025-09-09 17:54:21+00:00\"},{\"title\":\"Probing the Preferences of a Language Model: Integrating Verbal and Behavioral Tests of AI Welfare\",\"summary\":\"We develop new experimental paradigms for measuring welfare in language\\\\nmodels. We compare verbal reports of models about their preferences with\\\\npreferences expressed through behavior when navigating a virtual environment\\\\nand selecting conversation topics. We also test how costs and rewards affect\\\\nbehavior and whether responses to an eudaimonic welfare scale - measuring\\\\nstates such as autonomy and purpose in life - are consistent across\\\\nsemantically equivalent prompts. Overall, we observed a notable degree of\\\\nmutual support between our measures. The reliable correlations observed between\\\\nstated preferences and behavior across conditions suggest that preference\\\\nsatisfaction can, in principle, serve as an empirically measurable welfare\\\\nproxy in some of today\\'s AI systems. Furthermore, our design offered an\\\\nilluminating setting for qualitative observation of model behavior. Yet, the\\\\nconsistency between measures was more pronounced in some models and conditions\\\\nthan others and responses were not consistent across perturbations. Due to\\\\nthis, and the background uncertainty about the nature of welfare and the\\\\ncognitive states (and welfare subjecthood) of language models, we are currently\\\\nuncertain whether our methods successfully measure the welfare state of\\\\nlanguage models. Nevertheless, these findings highlight the feasibility of\\\\nwelfare measurement in language models, inviting further exploration.\",\"authors\":[\"Valen Tagliabue\",\"Leonard Dung\"],\"published\":\"2025-09-09 17:48:44+00:00\",\"updated\":\"2025-09-09 17:48:44+00:00\"},{\"title\":\"ACE and Diverse Generalization via Selective Disagreement\",\"summary\":\"Deep neural networks are notoriously sensitive to spurious correlations -\\\\nwhere a model learns a shortcut that fails out-of-distribution. Existing work\\\\non spurious correlations has often focused on incomplete\\\\ncorrelations,leveraging access to labeled instances that break the correlation.\\\\nBut in cases where the spurious correlations are complete, the correct\\\\ngeneralization is fundamentally \\\\\\\\textit{underspecified}. To resolve this\\\\nunderspecification, we propose learning a set of concepts that are consistent\\\\nwith training data but make distinct predictions on a subset of novel unlabeled\\\\ninputs. Using a self-training approach that encourages \\\\\\\\textit{confident} and\\\\n\\\\\\\\textit{selective} disagreement, our method ACE matches or outperforms existing\\\\nmethods on a suite of complete-spurious correlation benchmarks, while remaining\\\\nrobust to incomplete spurious correlations. ACE is also more configurable than\\\\nprior approaches, allowing for straight-forward encoding of prior knowledge and\\\\nprincipled unsupervised model selection. In an early application to\\\\nlanguage-model alignment, we find that ACE achieves competitive performance on\\\\nthe measurement tampering detection benchmark \\\\\\\\textit{without} access to\\\\nuntrusted measurements. While still subject to important limitations, ACE\\\\nrepresents significant progress towards overcoming underspecification.\",\"authors\":[\"Oliver Daniels\",\"Stuart Armstrong\",\"Alexandre Maranhão\",\"Mahirah Fairuz Rahman\",\"Benjamin M. Marlin\",\"Rebecca Gorman\"],\"published\":\"2025-09-09 17:43:05+00:00\",\"updated\":\"2025-09-09 17:43:05+00:00\"},{\"title\":\"Bringing Multi-Modal Multi-Task Federated Foundation Models to Education Domain: Prospects and Challenges\",\"summary\":\"Multi-modal multi-task (M3T) foundation models (FMs) have recently shown\\\\ntransformative potential in artificial intelligence, with emerging applications\\\\nin education. However, their deployment in real-world educational settings is\\\\nhindered by privacy regulations, data silos, and limited domain-specific data\\\\navailability. We introduce M3T Federated Foundation Models (FedFMs) for\\\\neducation: a paradigm that integrates federated learning (FL) with M3T FMs to\\\\nenable collaborative, privacy-preserving training across decentralized\\\\ninstitutions while accommodating diverse modalities and tasks. Subsequently,\\\\nthis position paper aims to unveil M3T FedFMs as a promising yet underexplored\\\\napproach to the education community, explore its potentials, and reveal its\\\\nrelated future research directions. We outline how M3T FedFMs can advance three\\\\ncritical pillars of next-generation intelligent education systems: (i) privacy\\\\npreservation, by keeping sensitive multi-modal student and institutional data\\\\nlocal; (ii) personalization, through modular architectures enabling tailored\\\\nmodels for students, instructors, and institutions; and (iii) equity and\\\\ninclusivity, by facilitating participation from underrepresented and\\\\nresource-constrained entities. We finally identify various open research\\\\nchallenges, including studying of (i) inter-institution heterogeneous privacy\\\\nregulations, (ii) the non-uniformity of data modalities\\' characteristics, (iii)\\\\nthe unlearning approaches for M3T FedFMs, (iv) the continual learning\\\\nframeworks for M3T FedFMs, and (v) M3T FedFM model interpretability, which must\\\\nbe collectively addressed for practical deployment.\",\"authors\":[\"Kasra Borazjani\",\"Naji Khosravan\",\"Rajeev Sahay\",\"Bita Akram\",\"Seyyedali Hosseinalipour\"],\"published\":\"2025-09-09 17:31:42+00:00\",\"updated\":\"2025-09-09 17:31:42+00:00\"},{\"title\":\"ImportSnare: Directed \\\\\"Code Manual\\\\\" Hijacking in Retrieval-Augmented Code Generation\",\"summary\":\"Code generation has emerged as a pivotal capability of Large Language\\\\nModels(LLMs), revolutionizing development efficiency for programmers of all\\\\nskill levels. However, the complexity of data structures and algorithmic logic\\\\noften results in functional deficiencies and security vulnerabilities in\\\\ngenerated code, reducing it to a prototype requiring extensive manual\\\\ndebugging. While Retrieval-Augmented Generation (RAG) can enhance correctness\\\\nand security by leveraging external code manuals, it simultaneously introduces\\\\nnew attack surfaces.\\\\n  In this paper, we pioneer the exploration of attack surfaces in\\\\nRetrieval-Augmented Code Generation (RACG), focusing on malicious dependency\\\\nhijacking. We demonstrate how poisoned documentation containing hidden\\\\nmalicious dependencies (e.g., matplotlib_safe) can subvert RACG, exploiting\\\\ndual trust chains: LLM reliance on RAG and developers\\' blind trust in LLM\\\\nsuggestions. To construct poisoned documents, we propose ImportSnare, a novel\\\\nattack framework employing two synergistic strategies: 1)Position-aware beam\\\\nsearch optimizes hidden ranking sequences to elevate poisoned documents in\\\\nretrieval results, and 2)Multilingual inductive suggestions generate\\\\njailbreaking sequences to manipulate LLMs into recommending malicious\\\\ndependencies. Through extensive experiments across Python, Rust, and\\\\nJavaScript, ImportSnare achieves significant attack success rates (over 50% for\\\\npopular libraries such as matplotlib and seaborn) in general, and is also able\\\\nto succeed even when the poisoning ratio is as low as 0.01%, targeting both\\\\ncustom and real-world malicious packages. Our findings reveal critical supply\\\\nchain risks in LLM-powered development, highlighting inadequate security\\\\nalignment for code generation tasks. To support future research, we will\\\\nrelease the multilingual benchmark suite and datasets. The project homepage is\\\\nhttps://importsnare.github.io.\",\"authors\":[\"Kai Ye\",\"Liangcai Su\",\"Chenxiong Qian\"],\"published\":\"2025-09-09 17:21:20+00:00\",\"updated\":\"2025-09-09 17:21:20+00:00\"}]', name='search_arxiv', tool_call_id='call_Y24jaUI54PwEmt1ArfL7iVkf')]}}\n",
            "{'tools': {'messages': [ToolMessage(content='{\\n  \"location\": {\\n    \"name\": \"New York\",\\n    \"region\": \"New York\",\\n    \"country\": \"United States of America\",\\n    \"lat\": 40.7142,\\n    \"lon\": -74.0064,\\n    \"tz_id\": \"America/New_York\",\\n    \"localtime_epoch\": 1757540824,\\n    \"localtime\": \"2025-09-10 17:47\"\\n  },\\n  \"current\": {\\n    \"last_updated_epoch\": 1757540700,\\n    \"last_updated\": \"2025-09-10 17:45\",\\n    \"temp_c\": 23.3,\\n    \"temp_f\": 73.9,\\n    \"is_day\": 1,\\n    \"condition\": {\\n      \"text\": \"Partly cloudy\",\\n      \"icon\": \"//cdn.weatherapi.com/weather/64x64/day/116.png\",\\n      \"code\": 1003\\n    },\\n    \"wind_mph\": 7.4,\\n    \"wind_kph\": 11.9,\\n    \"wind_degree\": 43,\\n    \"wind_dir\": \"NE\",\\n    \"pressure_mb\": 1020.0,\\n    \"pressure_in\": 30.11,\\n    \"precip_mm\": 0.0,\\n    \"precip_in\": 0.0,\\n    \"humidity\": 50,\\n    \"cloud\": 75,\\n    \"feelslike_c\": 25.0,\\n    \"feelslike_f\": 77.1,\\n    \"windchill_c\": 26.4,\\n    \"windchill_f\": 79.5,\\n    \"heatindex_c\": 27.7,\\n    \"heatindex_f\": 81.8,\\n    \"dewpoint_c\": 18.5,\\n    \"dewpoint_f\": 65.2,\\n    \"vis_km\": 16.0,\\n    \"vis_miles\": 9.0,\\n    \"uv\": 0.1,\\n    \"gust_mph\": 10.0,\\n    \"gust_kph\": 16.2\\n  }\\n}', name='weather_current', tool_call_id='call_w5YdUzjMcQFuQnAdbUozvj5S')]}}\n",
            "{'agent': {'messages': [AIMessage(content='Here are some of the latest research papers on Artificial Intelligence:\\n\\n1. \"Mini-o3: Scaling Up Reasoning Patterns and Interaction Turns for Visual Search\" — This work introduces Mini-o3, a system for deep, multi-turn reasoning in visual search tasks, achieving state-of-the-art performance. (Authors: Xin Lai et al., Published: 2025-09-09)\\n\\n2. \"Probing the Preferences of a Language Model: Integrating Verbal and Behavioral Tests of AI Welfare\" — This research explores measuring welfare in language models by comparing verbal reports and behavior. (Authors: Valen Tagliabue, Leonard Dung, Published: 2025-09-09)\\n\\n3. \"ACE and Diverse Generalization via Selective Disagreement\" — The paper discusses a method called ACE to overcome underspecification in deep neural networks related to spurious correlations. (Authors: Oliver Daniels et al., Published: 2025-09-09)\\n\\n4. \"Bringing Multi-Modal Multi-Task Federated Foundation Models to Education Domain: Prospects and Challenges\" — This introduces M3T Federated Foundation Models for privacy-preserving and collaborative AI training in education. (Authors: Kasra Borazjani et al., Published: 2025-09-09)\\n\\n5. \"ImportSnare: Directed \\'Code Manual\\' Hijacking in Retrieval-Augmented Code Generation\" — The study addresses security vulnerabilities in code generation aided by large language models and retrieval systems. (Authors: Kai Ye et al., Published: 2025-09-09)\\n\\nRegarding the weather in New York currently, it is partly cloudy with a temperature of about 23.3°C (73.9°F). The wind is coming from the northeast at around 7.4 mph (11.9 kph), humidity is at 50%, and there is no precipitation.\\n\\nIf you would like more details on any paper or the weather, please let me know!', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 398, 'prompt_tokens': 3178, 'total_tokens': 3576, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4.1-mini-2025-04-14', 'system_fingerprint': 'fp_4fce0778af', 'id': 'chatcmpl-CEMwDWIZjkxOCGYZci3d5SyaCibV7', 'service_tier': 'default', 'finish_reason': 'stop', 'logprobs': None}, id='run--92d20c6a-0060-4aa9-9786-eb20b3b5d0ea-0', usage_metadata={'input_tokens': 3178, 'output_tokens': 398, 'total_tokens': 3576, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})]}}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/jupyter_client/session.py:203: DeprecationWarning: datetime.datetime.utcnow() is deprecated and scheduled for removal in a future version. Use timezone-aware objects to represent datetimes in UTC: datetime.datetime.now(datetime.UTC).\n",
            "  return datetime.utcnow().replace(tzinfo=utc)\n",
            "\n",
            "\n",
            "╭────────────────────────────────────────────────────────────────────────────╮\n",
            "│                                                                            │\n",
            "│        _ __ ___  _____           __  __  _____________    ____    ____     │\n",
            "│       _ __ ___ .'____/___ ______/ /_/  |/  / ____/ __ \\  |___ \\  / __ \\    │\n",
            "│      _ __ ___ / /_  / __ `/ ___/ __/ /|_/ / /   / /_/ /  ___/ / / / / /    │\n",
            "│     _ __ ___ / __/ / /_/ (__  ) /_/ /  / / /___/ ____/  /  __/_/ /_/ /     │\n",
            "│    _ __ ___ /_/    \\____/____/\\__/_/  /_/\\____/_/      /_____(*)____/      │\n",
            "│                                                                            │\n",
            "│                                                                            │\n",
            "│                                FastMCP  2.0                                │\n",
            "│                                                                            │\n",
            "│                                                                            │\n",
            "│                 🖥️  Server name:     ArxivMCP                               │\n",
            "│                 📦 Transport:       STDIO                                  │\n",
            "│                                                                            │\n",
            "│                 🏎️  FastMCP version: 2.12.2                                 │\n",
            "│                 🤝 MCP SDK version: 1.13.1                                 │\n",
            "│                                                                            │\n",
            "│                 📚 Docs:            https://gofastmcp.com                  │\n",
            "│                 🚀 Deploy:          https://fastmcp.cloud                  │\n",
            "│                                                                            │\n",
            "╰────────────────────────────────────────────────────────────────────────────╯\n",
            "\n",
            "\n",
            "[09/10/25 21:46:34] INFO     Starting MCP server 'ArxivMCP' with  server.py:1493\n",
            "                             transport 'stdio'                                  \n",
            "2025-09-10 21:46:34,209 INFO Processing request of type ListToolsRequest\n",
            "2025-09-10 21:46:39,571 INFO Processing request of type CallToolRequest\n",
            "2025-09-10 21:46:39,571 INFO Requesting https://api.weatherapi.com/v1/current.json with params {'q': 'New York', 'aqi': 'no', 'key': '87af948f625a41298ee211736251807'}\n",
            "\n",
            "\n",
            "╭────────────────────────────────────────────────────────────────────────────╮\n",
            "│                                                                            │\n",
            "│        _ __ ___  _____           __  __  _____________    ____    ____     │\n",
            "│       _ __ ___ .'____/___ ______/ /_/  |/  / ____/ __ \\  |___ \\  / __ \\    │\n",
            "│      _ __ ___ / /_  / __ `/ ___/ __/ /|_/ / /   / /_/ /  ___/ / / / / /    │\n",
            "│     _ __ ___ / __/ / /_/ (__  ) /_/ /  / / /___/ ____/  /  __/_/ /_/ /     │\n",
            "│    _ __ ___ /_/    \\____/____/\\__/_/  /_/\\____/_/      /_____(*)____/      │\n",
            "│                                                                            │\n",
            "│                                                                            │\n",
            "│                                FastMCP  2.0                                │\n",
            "│                                                                            │\n",
            "│                                                                            │\n",
            "│                 🖥️  Server name:     ArxivMCP                               │\n",
            "│                 📦 Transport:       STDIO                                  │\n",
            "│                                                                            │\n",
            "│                 🏎️  FastMCP version: 2.12.2                                 │\n",
            "│                 🤝 MCP SDK version: 1.13.1                                 │\n",
            "│                                                                            │\n",
            "│                 📚 Docs:            https://gofastmcp.com                  │\n",
            "│                 🚀 Deploy:          https://fastmcp.cloud                  │\n",
            "│                                                                            │\n",
            "╰────────────────────────────────────────────────────────────────────────────╯\n",
            "\n",
            "\n",
            "[09/10/25 21:46:39] INFO     Starting MCP server 'ArxivMCP' with  server.py:1493\n",
            "                             transport 'stdio'                                  \n",
            "2025-09-10 21:46:39,870 INFO HTTP Request: GET https://api.weatherapi.com/v1/current.json?q=New+York&aqi=no&key=87af948f625a41298ee211736251807 \"HTTP/1.1 200 OK\"\n",
            "2025-09-10 21:46:39,871 INFO WeatherAPI success: https://api.weatherapi.com/v1/current.json\n",
            "2025-09-10 21:46:39,873 INFO Processing request of type ListToolsRequest\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uSCy8RHJn8ms"
      },
      "source": [
        "## 4.9 Key Takeaways and Production Deployment\n",
        "\n",
        "### What You've Accomplished\n",
        "\n",
        "Congratulations! You've mastered the complete MCP ecosystem and built production-ready integrations:\n",
        "\n",
        "✅ **MCP Protocol Understanding** - Learned the fundamentals of Model Context Protocol  \n",
        "✅ **FastMCP Server Development** - Built comprehensive servers with proper validation  \n",
        "✅ **LangGraph Agent Integration** - Created real agents using official MCP adapters  \n",
        "✅ **Production Deployment** - Standalone servers supporting multiple transports  \n",
        "✅ **Multi-Server Architectures** - Understanding of complex agent workflows  \n",
        "✅ **Security and Best Practices** - Error handling, validation, and safe operations  \n",
        "\n",
        "### Complete Workflow Mastered\n",
        "\n",
        "```\n",
        "1. 🔧 Design MCP Server    → Define tools, resources, and business logic\n",
        "2. 📝 Implement with FastMCP → Use decorators and type hints for clean APIs  \n",
        "3. 🧪 Test Thoroughly      → Validate all edge cases and error conditions\n",
        "4. 📦 Package for Deployment → Create standalone executables\n",
        "5. 🤖 Integrate with Agents → Use MultiServerMCPClient and create_react_agent\n",
        "6. 🚀 Deploy to Production → Support HTTP transport, monitoring, scaling\n",
        "```\n",
        "\n",
        "### Technical Skills Developed\n",
        "\n",
        "**MCP Server Development:**\n",
        "- Tool registration with `@mcp.tool()` decorator\n",
        "- Automatic JSON schema generation from type hints\n",
        "- Comprehensive error handling and validation\n",
        "- Resource management and server introspection\n",
        "- Support for both stdio and HTTP transports\n",
        "\n",
        "**LangGraph Integration:**\n",
        "- **MultiServerMCPClient** configuration for multiple servers\n",
        "- **Automatic tool discovery** from MCP servers  \n",
        "- **ReAct agent creation** with `create_react_agent`\n",
        "- **Natural language processing** of complex queries\n",
        "- **Multi-step problem solving** using multiple tools\n",
        "\n",
        "**Production Features:**\n",
        "- Standalone server deployment patterns\n",
        "- HTTP transport for production scalability\n",
        "- Proper error handling at all integration layers\n",
        "- Security considerations and input validation\n",
        "- Monitoring and observability patterns\n",
        "\n",
        "### Real-World Applications Unlocked\n",
        "\n",
        "This MCP foundation enables you to build:\n",
        "\n",
        "**Enterprise AI Systems:**\n",
        "- Connect agents to databases, CRMs, and internal APIs\n",
        "- Automate complex business workflows across multiple systems\n",
        "- Provide AI access to company knowledge bases and documentation\n",
        "- Build custom tool ecosystems for specific business domains\n",
        "\n",
        "**Developer Tools and Automation:**\n",
        "- AI coding assistants with access to version control and CI/CD\n",
        "- Automated testing, deployment, and monitoring tools\n",
        "- Integration with IDEs, build systems, and project management\n",
        "- Code review and documentation generation systems\n",
        "\n",
        "**Data Science and Analytics:**\n",
        "- AI agents that query data warehouses and visualization tools\n",
        "- Automated report generation and insight discovery\n",
        "- Integration with ML pipelines and experiment tracking\n",
        "- Real-time data analysis and decision support systems\n",
        "\n",
        "### Multi-Server Agent Architectures\n",
        "\n",
        "You now understand how to build sophisticated agents that combine tools from different domains:\n",
        "\n",
        "```python\n",
        "# Production multi-server configuration\n",
        "server_config = {\n",
        "    \"math\": {\n",
        "        \"command\": \"python\",\n",
        "        \"args\": [\"/opt/mcp/math_server.py\"],\n",
        "        \"transport\": \"stdio\"\n",
        "    },\n",
        "    \"weather\": {\n",
        "        \"url\": \"http://weather-api:8001\",\n",
        "        \"transport\": \"http\",\n",
        "        \"timeout\": 30\n",
        "    },\n",
        "    \"database\": {\n",
        "        \"url\": \"http://db-gateway:8002\",\n",
        "        \"transport\": \"http\",\n",
        "        \"auth\": {\"api_key\": \"${DB_API_KEY}\"}\n",
        "    },\n",
        "    \"analytics\": {\n",
        "        \"command\": \"python\",\n",
        "        \"args\": [\"/opt/mcp/analytics_server.py\"],\n",
        "        \"transport\": \"stdio\",\n",
        "        \"env\": {\"DATA_SOURCE\": \"${ANALYTICS_DB_URL}\"}\n",
        "    }\n",
        "}\n",
        "\n",
        "# Agent can seamlessly use tools from all servers\n",
        "client = MultiServerMCPClient(server_config)\n",
        "agent = create_react_agent(llm, await client.get_tools())\n",
        "```\n",
        "\n",
        "### Next Steps in Your MCP Journey\n",
        "\n",
        "**Immediate Actions:**\n",
        "1. **Complete Lab 5A** - Build the comprehensive math operations server\n",
        "2. **Complete Lab 5B** - Create the weather API server with caching\n",
        "3. **Experiment with Multi-Server Setups** - Combine different tool types\n",
        "4. **Deploy to Production** - Use HTTP transport and monitoring\n",
        "\n",
        "**Advanced Exploration:**\n",
        "- **Custom Transport Protocols** - Build WebSocket or gRPC transports\n",
        "- **Authentication and Authorization** - Implement secure access patterns\n",
        "- **Monitoring and Observability** - Add metrics, logging, and health checks\n",
        "- **Performance Optimization** - Caching, connection pooling, load balancing\n",
        "- **Enterprise Integration** - Connect to existing business systems\n",
        "\n",
        "### Production Deployment Checklist\n",
        "\n",
        "Before deploying MCP servers to production:\n",
        "\n",
        "- [ ] **Security**: Authentication, input validation, rate limiting\n",
        "- [ ] **Error Handling**: Graceful failures and detailed error messages  \n",
        "- [ ] **Monitoring**: Health checks, metrics, and logging\n",
        "- [ ] **Performance**: Caching, connection pooling, timeout handling\n",
        "- [ ] **Documentation**: API documentation and usage examples\n",
        "- [ ] **Testing**: Unit tests, integration tests, load testing\n",
        "- [ ] **Deployment**: Container images, configuration management\n",
        "- [ ] **Scaling**: Load balancing, horizontal scaling patterns\n",
        "\n",
        "### The MCP Ecosystem Advantage\n",
        "\n",
        "By mastering MCP, you're part of a growing ecosystem that enables:\n",
        "- **Interoperability** - Tools work across different AI platforms\n",
        "- **Reusability** - One server serves many agent applications\n",
        "- **Scalability** - Efficient client-server architecture\n",
        "- **Maintainability** - Clear separation of concerns\n",
        "- **Innovation** - Focus on business logic, not integration plumbing\n",
        "\n",
        "---\n",
        "\n",
        "**🎉 Congratulations!** You're now equipped to build production-ready MCP servers and integrate them with sophisticated LangGraph agents. The foundation you've built here will serve you well as you create the next generation of AI-powered applications.\n",
        "\n",
        "**Ready for hands-on implementation?** Continue to the lab exercises to put these concepts into practice with real code and working examples!"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
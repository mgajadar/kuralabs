{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# LangGraph Essentials - Lab\n",
        "## Building A Disaster Response/Notification Agent System\n",
        "\n",
        "In this lab activity, you will implement a multi-agent disaster response notification system that checks national and local news for disaster related information. The system will also have a"
      ],
      "metadata": {
        "id": "bbyoA60g6SVW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Environment Setup"
      ],
      "metadata": {
        "id": "DYsaxmQc6Xz4"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "UixBQbH95iw4"
      },
      "outputs": [],
      "source": [
        "%%capture --no-stderr\n",
        "%pip install langchain langchain-openai langchain-google-genai langgraph gradio"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from getpass import getpass\n",
        "\n",
        "keys = [\n",
        "    \"OPENAI_API_KEY\",\n",
        "    \"GOOGLE_API_KEY\",\n",
        "    \"GNEWS_API_KEY\",\n",
        "    \"WEATHER_API_KEY\",\n",
        "    \"IP_ADDRESS\"\n",
        "]\n",
        "\n",
        "for key in keys:\n",
        "  value = getpass(f\"{key} (press enter to skip if not inputting key):\")\n",
        "  if value == \"\" or value is None:\n",
        "    continue\n",
        "  os.environ[key] = value\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9Gk3_E039Ui2",
        "outputId": "a8d78941-673e-4cd6-d91e-fadaba3f4bbc"
      },
      "execution_count": 2,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "OPENAI_API_KEY (press enter to skip if not inputting key):··········\n",
            "GOOGLE_API_KEY (press enter to skip if not inputting key):··········\n",
            "GNEWS_API_KEY (press enter to skip if not inputting key):··········\n",
            "WEATHER_API_KEY (press enter to skip if not inputting key):··········\n",
            "IP_ADDRESS (press enter to skip if not inputting key):··········\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Agent Tools\n",
        "\n",
        "Here we are defining the tools that our agents will have access to:\n",
        "\n",
        "- **Disaster RSS Tool**: This tool aggregates disaster-related news feeds and creates a summary of the contents.\n",
        "- **Geolocation Tool**: This tool captures the geolocation of the user based on their IP address.\n",
        "- **Local News Tool**: This tool gets local news for the user based on location.\n",
        "- **Local Weather Tool**: This tool gets the local weather forecast for a user based on their location."
      ],
      "metadata": {
        "id": "-uHdVfoHBI8w"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from typing import List, Optional\n",
        "from langchain_openai import ChatOpenAI\n",
        "from langchain_core.prompts import ChatPromptTemplate\n",
        "from pydantic import BaseModel, Field\n",
        "import requests\n",
        "import ipaddress\n",
        "from datetime import datetime\n",
        "from langchain_core.tools import tool\n",
        "from getpass import getpass  # For secure key input\n",
        "from langgraph.graph import StateGraph, END\n",
        "from langgraph.checkpoint.memory import InMemorySaver\n",
        "from langgraph.prebuilt.chat_agent_executor import create_react_agent\n",
        "from langgraph.types import Command\n",
        "from langgraph.errors import GraphRecursionError\n",
        "from langchain_core.runnables.config import RunnableConfig\n",
        "\n",
        "# --- Initialize a general purpose summarizer ---\n",
        "summarizer_prompt = ChatPromptTemplate.from_messages([\n",
        "    (\"system\", \"You are a helpful assistant that summarizes text, focusing on disaster-related events with dates, locations, and severity.\"),\n",
        "    (\"human\", \"{text}\")\n",
        "])\n",
        "summarizer_llm = init_chat_model(model_provider=\"google_genai\", model=\"gemini-2.5-flash\")\n",
        "summarizer = summarizer_prompt | summarizer_llm\n",
        "\n",
        "# --- Helper: Safe GET ---\n",
        "def fetch_and_parse_url(url: str, params: Optional[Dict[str, Any]] = None, timeout: int = 10) -> Any:\n",
        "    \"\"\"A helper function to run GET requests, handling errors gracefully.\"\"\"\n",
        "    try:\n",
        "        response = requests.get(url, params=params, timeout=timeout)\n",
        "        response.raise_for_status()\n",
        "        try:\n",
        "            return response.json()\n",
        "        except ValueError:\n",
        "            return response.text\n",
        "    except requests.RequestException as e:\n",
        "        return f\"error fetching {url}: {str(e)}\"\n",
        "\n",
        "# --- Tools ---\n",
        "\n",
        "@tool\n",
        "def get_public_ip() -> str:\n",
        "    \"\"\"Fetches the current public IP address.\"\"\"\n",
        "    try:\n",
        "        response = requests.get(\"https://api.ipify.org?format=json\", timeout=10)\n",
        "        return response.json().get(\"ip\", \"\")\n",
        "    except Exception:\n",
        "        raise ValueError(\"Unable to fetch public IP\")\n",
        "\n",
        "@tool\n",
        "def geolocation(ip: Optional[str] = None) -> Dict[str, Any]:\n",
        "    \"\"\"Gathers location data based on a given IPv4 address. Suggests manual input if fetch fails.\"\"\"\n",
        "    if not ip:\n",
        "        ip = os.getenv(\"IP_ADDRESS\")\n",
        "        if not ip:\n",
        "            try:\n",
        "                ip = get_public_ip()\n",
        "            except ValueError:\n",
        "                return {\"error\": \"Unable to fetch IP\", \"suggestion\": \"Please provide a city name\"}\n",
        "    try:\n",
        "        ipaddress.ip_address(ip)\n",
        "    except ValueError:\n",
        "        return {\"error\": f\"Invalid IP format: {ip}\", \"suggestion\": \"Please provide a city name\"}\n",
        "    url = f\"http://ip-api.com/json/{ip}\"\n",
        "    response = fetch_and_parse_url(url)\n",
        "    if isinstance(response, dict) and response.get(\"status\") == \"fail\":\n",
        "        return {\"error\": response.get(\"message\"), \"suggestion\": \"Please provide a city name\"}\n",
        "    return response if isinstance(response, dict) else {\"error\": \"Invalid response\", \"suggestion\": \"Please provide a city name\"}\n",
        "\n",
        "@tool\n",
        "def disaster_rss_summary() -> str:\n",
        "    \"\"\"Aggregates disaster-related news feeds and summarizes contents for the last 7 days.\"\"\"\n",
        "    current_date = datetime.now().strftime(\"%Y-%m-%d\")  # e.g., 2025-09-10\n",
        "    feeds = [\n",
        "        f\"https://news.google.com/rss/search?q=natural+disasters+when:{current_date}-7d\",\n",
        "        \"https://www.fema.gov/feeds/disasters-major.rss\",\n",
        "        \"https://www.fema.gov/feeds/disasters-fire.rss\"\n",
        "    ]\n",
        "    feed_responses = [fetch_and_parse_url(feed) for feed in feeds]\n",
        "    text_input = \"\\n\".join(str(response) for response in feed_responses)\n",
        "    summary = summarizer.invoke({\"text\": text_input})\n",
        "    return summary.content if hasattr(summary, \"content\") else str(summary)\n",
        "\n",
        "@tool\n",
        "def local_news(query: str, max_results: int = 10) -> Dict[str, Any]:\n",
        "    \"\"\"Retrieves the latest news based on the given query.\"\"\"\n",
        "    api_key = os.getenv(\"GNEWS_API_KEY\")\n",
        "    if not api_key:\n",
        "        return {\"error\": \"Missing GNEWS_API_KEY\", \"suggestion\": \"Please set GNEWS_API_KEY\"}\n",
        "    params = {\"q\": query, \"max\": max_results, \"apikey\": api_key}\n",
        "    url = \"https://gnews.io/api/v4/search\"\n",
        "    response = fetch_and_parse_url(url, params=params)\n",
        "    return response if isinstance(response, dict) else {\"error\": \"Invalid news response\"}\n",
        "\n",
        "@tool\n",
        "def local_weather(lat: float, lon: float) -> Dict[str, Any]:\n",
        "    \"\"\"Retrieves the local weather based on the given location.\"\"\"\n",
        "    api_key = os.getenv(\"WEATHER_API_KEY\")\n",
        "    if not api_key:\n",
        "        return {\"error\": \"Missing WEATHER_API_KEY\", \"suggestion\": \"Please set WEATHER_API_KEY\"}\n",
        "    params = {\"lat\": lat, \"lon\": lon, \"appid\": api_key, \"units\": \"metric\"}\n",
        "    url = \"https://api.openweathermap.org/data/2.5/weather\"\n",
        "    response = fetch_and_parse_url(url, params=params)\n",
        "    return response if isinstance(response, dict) else {\"error\": \"Invalid weather response\"}"
      ],
      "metadata": {
        "id": "i3j6Uivi9s7Y"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Define the Agent State"
      ],
      "metadata": {
        "id": "tySeLkNsG4jj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from typing import TypedDict, List, Dict, Any\n",
        "\n",
        "class DisasterState(TypedDict, total=False):\n",
        "    input: str                        # the current user prompt\n",
        "    messages: List[Dict[str, Any]]    # conversation turns accumulated by the agent\n",
        "\n",
        "    # optional convenience fields that tools/agent may fill\n",
        "    ip: str                           # detected public IP\n",
        "    location: str                     # \"City, Region\" derived from geolocation\n",
        "    geo: Dict[str, Any]               # full geolocation payload (ip-api result)\n",
        "    news: Dict[str, Any]              # raw GNews response (if fetched)\n",
        "    weather: Dict[str, Any]           # raw weather response (if fetched)\n"
      ],
      "metadata": {
        "id": "cg-rjephDjXQ"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Define the Agent Roles and Chains"
      ],
      "metadata": {
        "id": "iCOUuvbbHSnH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the system prompt and appropriate chains for each agent (e.g. StructuredOutput, etc.)\n",
        "\n",
        "llm = ChatOpenAI(model=\"gpt-4o-mini\", temperature=0)\n",
        "\n",
        "# tools\n",
        "TOOLS = [\n",
        "    get_public_ip,      # new: auto-detect IP if env var not set\n",
        "    geolocation,        # accepts ip or auto-fetches via get_public_ip\n",
        "    local_news,         # GNews (needs GNEWS_API_KEY)\n",
        "    local_weather,      # OpenWeather (needs WEATHER_API_KEY)\n",
        "    disaster_rss_summary,  # optional: global disaster feeds summary\n",
        "]\n",
        "\n",
        "# how the agent should behave\n",
        "AGENT_SYS = \"\"\"\n",
        "You are a disaster advisory assistant. Use ReAct: think, use tools, then answer.\n",
        "1) Determine user's location with get_public_ip then geolocation. If that fails, ask the user to provide a city.\n",
        "2) Always check disaster_rss_summary for national/global disasters. Then pull relevant local_news and local_weather if keys are available.\n",
        "3) Produce a concise 24–72h advisory with 3–6 specific actions, incorporating RSS data even if local tools fail.\n",
        "Be factual, avoid hype, cite sources/links when available, and explain briefly why actions are recommended.\n",
        "\"\"\"\n",
        "\n",
        "# state modifier prompt (pre/appends system instructions to the agent loop)\n",
        "agent_prompt = ChatPromptTemplate.from_messages([\n",
        "    (\"system\", AGENT_SYS),\n",
        "    (\"human\", \"{input}\")\n",
        "])\n",
        "\n",
        "# single ReAct agent that will pick tools as needed\n",
        "react_agent = create_react_agent(\n",
        "    model=llm,\n",
        "    tools=TOOLS,\n",
        "    prompt=AGENT_SYS,\n",
        ")"
      ],
      "metadata": {
        "id": "mgqP1VcgHbid"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Define the Agent Nodes"
      ],
      "metadata": {
        "id": "8LZCJVMsHcoX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Agent Nodes\n",
        "from typing import Dict, Any, Optional\n",
        "from langchain_core.runnables.config import RunnableConfig\n",
        "\n",
        "DisasterState = Dict[str, Any]\n",
        "\n",
        "DEFAULT_PROMPT = (\n",
        "    \"Please determine my location using the tools, then give a concise 24–72h \"\n",
        "    \"disaster advisory with specific actions.\"\n",
        ")\n",
        "\n",
        "def agent_node(state: DisasterState, config: Optional[RunnableConfig] = None) -> DisasterState:\n",
        "    \"\"\"\n",
        "    Delegates to the prebuilt ReAct agent.\n",
        "    Expects state to contain an 'input' string; provides a safe default if missing.\n",
        "    \"\"\"\n",
        "    if not state.get(\"input\"):\n",
        "        state[\"input\"] = DEFAULT_PROMPT\n",
        "    # react_agent comes from the previous cell (create_react_agent)\n",
        "    return react_agent.invoke(state, config)\n"
      ],
      "metadata": {
        "id": "DWnjm6p5Hf6A"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Create and Compile the Graph"
      ],
      "metadata": {
        "id": "LNtIv8f5HgcB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "builder = StateGraph(DisasterState)\n",
        "\n",
        "builder.add_node(\"agent\", agent_node)\n",
        "\n",
        "# entry point → agent → END\n",
        "builder.set_entry_point(\"agent\")\n",
        "builder.add_edge(\"agent\", END)\n",
        "\n",
        "# compile with checkpointer\n",
        "graph = builder.compile(checkpointer=InMemorySaver())"
      ],
      "metadata": {
        "id": "QgRgnpG6HiwT"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Set up the UI with Gradio"
      ],
      "metadata": {
        "id": "O6rND85Adzch"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import gradio as gr\n",
        "from uuid import uuid4\n",
        "\n",
        "SESSION_NS = \"react-ui\"\n",
        "thread_state = gr.State(value=\"\")  # Persisted across turns\n",
        "\n",
        "def disaster_response_agent(message: str, history: List[Dict[str, Any]], thread_id: str):\n",
        "    # Allocate a stable thread ID for the checkpointer if none provided\n",
        "    if not thread_id:\n",
        "        thread_id = f\"ui-{uuid4()}\"\n",
        "\n",
        "    user_input = message.strip() or (\n",
        "        \"please determine my location using the tools, then give a concise 24–72h \"\n",
        "        \"disaster advisory with 3–6 specific actions.\"\n",
        "    )\n",
        "\n",
        "    # Use messages with the ReAct executor\n",
        "    cfg = {\"configurable\": {\"thread_id\": thread_id, \"checkpoint_ns\": SESSION_NS}}\n",
        "    final_state = graph.invoke({\"messages\": [{\"role\": \"user\", \"content\": user_input}]}, cfg)\n",
        "\n",
        "    # Pull last assistant reply from the conversation\n",
        "    msgs = final_state.get(\"messages\", [])\n",
        "    out = \"no response\"\n",
        "    if msgs:\n",
        "        for m in reversed(msgs):\n",
        "            if hasattr(m, 'role'):\n",
        "                role = m.role.lower()\n",
        "            else:\n",
        "                role = getattr(m, 'type', '').lower()\n",
        "            if role in (\"assistant\", \"ai\") and hasattr(m, 'content') and m.content:\n",
        "                out = m.content\n",
        "                break\n",
        "        else:\n",
        "            out = msgs[-1].content if hasattr(msgs[-1], 'content') else str(msgs[-1])\n",
        "\n",
        "    # Return the response and the current thread_id (Gradio will update state)\n",
        "    return out, thread_id  # Tuple return: (response, updated_thread_id)\n",
        "\n",
        "# Update ChatInterface with explicit inputs and outputs\n",
        "gr.ChatInterface(\n",
        "    fn=disaster_response_agent,\n",
        "    title=\"Disaster Agent\",\n",
        "    type=\"messages\",\n",
        "    additional_inputs=[thread_state],  # Pass thread_id as input\n",
        "    additional_outputs=[thread_state],  # Update thread_state with the returned thread_id\n",
        ").launch(debug=True)"
      ],
      "metadata": {
        "id": "bst6ln-7d1lD",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 660
        },
        "outputId": "553d2ed3-c02b-4bb4-d05a-f65aba180279"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "It looks like you are running Gradio on a hosted Jupyter notebook, which requires `share=True`. Automatically setting `share=True` (you can turn this off by setting `share=False` in `launch()` explicitly).\n",
            "\n",
            "Colab notebook detected. This cell will run indefinitely so that you can see errors and logs. To turn off, set debug=False in launch().\n",
            "* Running on public URL: https://5f3a03729f64e78749.gradio.live\n",
            "\n",
            "This share link expires in 1 week. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div><iframe src=\"https://5f3a03729f64e78749.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Keyboard interruption in main thread... closing server.\n",
            "Killing tunnel 127.0.0.1:7860 <> https://5f3a03729f64e78749.gradio.live\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    }
  ]
}